{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## オートエンコーダ(AE)による特徴量エンジニアリング\n",
    "\n",
    "特徴量セットB (`df_processed_b`) をAEに入力し、低次元の特徴量表現を獲得します。\n",
    "TensorFlow (Keras) が必要です: pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. CSVデータの読み込み ---\n",
      "'BTCUSDT_5m_processed_set_b.csv' を読み込みました。\n",
      "\n",
      "--- 2. データ分割 ---\n",
      "元の特徴量の数: 59\n",
      "学習データ数: 426804, テストデータ数: 106701\n",
      "\n",
      "--- 3. データ準備 (スケーリング) ---\n",
      "スケーリング完了。\n",
      "\n",
      "--- 4. オートエンコーダモデル定義 ---\n",
      "エンコーディング次元数: 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"autoencoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,840</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ encoder_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,835</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m3,840\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ encoder_output (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m544\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m2,112\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m)             │         \u001b[38;5;34m3,835\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,707</span> (53.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,707\u001b[0m (53.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,323</span> (52.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,323\u001b[0m (52.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 5. AEモデルのコンパイルと学習 ---\n",
      "AE学習中...\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.5829 - val_loss: 0.3515\n",
      "Epoch 2/50\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2156 - val_loss: 0.3381\n",
      "Epoch 3/50\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.1903 - val_loss: 0.3059\n",
      "Epoch 4/50\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.1745 - val_loss: 0.3190\n",
      "Epoch 5/50\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.1597 - val_loss: 0.3210\n",
      "Epoch 6/50\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.1507 - val_loss: 0.3253\n",
      "Epoch 7/50\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.1471 - val_loss: 0.3144\n",
      "Epoch 8/50\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.1413 - val_loss: 0.2745\n",
      "Epoch 9/50\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.1349 - val_loss: 0.2756\n",
      "Epoch 10/50\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.1321 - val_loss: 0.2423\n",
      "Epoch 11/50\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.1296 - val_loss: 0.2126\n",
      "Epoch 12/50\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.1269 - val_loss: 0.1936\n",
      "Epoch 13/50\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.1293 - val_loss: 0.1747\n",
      "Epoch 14/50\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.1257 - val_loss: 0.1742\n",
      "Epoch 15/50\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.1248 - val_loss: 0.1651\n",
      "Epoch 16/50\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.1232 - val_loss: 0.2159\n",
      "Epoch 17/50\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.1215 - val_loss: 0.1945\n",
      "Epoch 18/50\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.1218 - val_loss: 0.1805\n",
      "Epoch 19/50\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.1190 - val_loss: 0.1739\n",
      "Epoch 20/50\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.1186 - val_loss: 0.1650\n",
      "Epoch 21/50\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.1157 - val_loss: 0.1710\n",
      "Epoch 22/50\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.1195 - val_loss: 0.1717\n",
      "Epoch 23/50\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.1176 - val_loss: 0.1465\n",
      "Epoch 24/50\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.1146 - val_loss: 0.1614\n",
      "Epoch 25/50\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.1185 - val_loss: 0.1573\n",
      "Epoch 26/50\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.1154 - val_loss: 0.1450\n",
      "Epoch 27/50\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.1142 - val_loss: 0.1536\n",
      "Epoch 28/50\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.1145 - val_loss: 0.1561\n",
      "Epoch 29/50\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.1145 - val_loss: 0.1706\n",
      "Epoch 30/50\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.1138 - val_loss: 0.1435\n",
      "Epoch 31/50\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.1137 - val_loss: 0.1602\n",
      "Epoch 32/50\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.1122 - val_loss: 0.1538\n",
      "Epoch 33/50\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.1147 - val_loss: 0.1366\n",
      "Epoch 34/50\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.1131 - val_loss: 0.1563\n",
      "Epoch 35/50\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.1143 - val_loss: 0.1438\n",
      "Epoch 36/50\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.1130 - val_loss: 0.1563\n",
      "Epoch 37/50\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.1113 - val_loss: 0.1345\n",
      "Epoch 38/50\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.1122 - val_loss: 0.1426\n",
      "Epoch 39/50\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.1116 - val_loss: 0.1336\n",
      "Epoch 40/50\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.1103 - val_loss: 0.1484\n",
      "Epoch 41/50\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.1130 - val_loss: 0.1381\n",
      "Epoch 42/50\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.1102 - val_loss: 0.1455\n",
      "Epoch 43/50\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.1109 - val_loss: 0.1400\n",
      "Epoch 44/50\n",
      "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.1118 - val_loss: 0.1348\n",
      "AE学習完了。所要時間: 83.19 秒\n",
      "最終的な検証損失 (Val Loss): 0.134801\n",
      "\n",
      "--- 6. エンコーダによる特徴量変換 ---\n",
      "\u001b[1m13338/13338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 361us/step\n",
      "\u001b[1m3335/3335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 364us/step\n",
      "変換後の学習データ形状: (426804, 16)\n",
      "変換後のテストデータ形状: (106701, 16)\n",
      "特徴量変換完了。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "import time\n",
    "\n",
    "# --- 1. データの読み込み ---\n",
    "print(\"--- 1. CSVデータの読み込み ---\")\n",
    "csv_filename = 'BTCUSDT_5m_processed_set_b.csv'\n",
    "try:\n",
    "    df_processed_b_loaded = pd.read_csv(csv_filename, index_col='timestamp', parse_dates=True)\n",
    "    print(f\"'{csv_filename}' を読み込みました。\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"エラー: ファイル '{csv_filename}' が見つかりません。\")\n",
    "    df_processed_b_loaded = None\n",
    "except Exception as e:\n",
    "    print(f\"CSV読み込み中にエラーが発生しました: {e}\")\n",
    "    df_processed_b_loaded = None\n",
    "\n",
    "# --- 2. データ分割 ---\n",
    "if df_processed_b_loaded is not None and not df_processed_b_loaded.empty:\n",
    "    print(\"\\n--- 2. データ分割 ---\")\n",
    "    exclude_cols = ['open', 'high', 'low', 'close', 'volume', 'turnover', 'wclprice', 'target']\n",
    "    features_b = [col for col in df_processed_b_loaded.columns if col not in exclude_cols]\n",
    "    n_original_features = len(features_b)\n",
    "    print(f\"元の特徴量の数: {n_original_features}\")\n",
    "\n",
    "    X_b = df_processed_b_loaded[features_b]\n",
    "    y_b = df_processed_b_loaded['target'] # y はAE学習には使わないが、後で使う\n",
    "\n",
    "    test_size = 0.2\n",
    "    X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(\n",
    "        X_b, y_b, test_size=test_size, shuffle=False\n",
    "    )\n",
    "    print(f\"学習データ数: {len(X_train_b)}, テストデータ数: {len(X_test_b)}\")\n",
    "\n",
    "    # --- 3. データ準備 (スケーリング) ---\n",
    "    print(\"\\n--- 3. データ準備 (スケーリング) ---\")\n",
    "    scaler_ae = StandardScaler() # AE用に新しいスケーラー\n",
    "    X_train_scaled = scaler_ae.fit_transform(X_train_b)\n",
    "    X_test_scaled = scaler_ae.transform(X_test_b)\n",
    "    print(\"スケーリング完了。\")\n",
    "\n",
    "    # --- 4. オートエンコーダ(AE)モデルの定義 ---\n",
    "    print(\"\\n--- 4. オートエンコーダモデル定義 ---\")\n",
    "    encoding_dim = 16  # 圧縮後の次元数 (ハイパーパラメータ、元の66次元から削減)\n",
    "    print(f\"エンコーディング次元数: {encoding_dim}\")\n",
    "\n",
    "    # 入力層\n",
    "    input_layer = keras.Input(shape=(n_original_features,))\n",
    "\n",
    "    # エンコーダ部分\n",
    "    encoded = layers.Dense(64, activation='relu')(input_layer)\n",
    "    encoded = layers.BatchNormalization()(encoded)\n",
    "    encoded = layers.Dropout(0.1)(encoded)\n",
    "    encoded = layers.Dense(32, activation='relu')(encoded)\n",
    "    encoded = layers.BatchNormalization()(encoded)\n",
    "    encoded = layers.Dropout(0.1)(encoded)\n",
    "    encoder_output = layers.Dense(encoding_dim, activation='relu', name='encoder_output')(encoded) # ボトルネック層\n",
    "\n",
    "    # デコーダ部分\n",
    "    decoded = layers.Dense(32, activation='relu')(encoder_output)\n",
    "    decoded = layers.BatchNormalization()(decoded)\n",
    "    decoded = layers.Dropout(0.1)(decoded)\n",
    "    decoded = layers.Dense(64, activation='relu')(decoded)\n",
    "    decoded = layers.BatchNormalization()(decoded)\n",
    "    decoded = layers.Dropout(0.1)(decoded)\n",
    "    decoded = layers.Dense(n_original_features, activation='linear')(decoded) # 出力層は元の次元数、活性化は線形\n",
    "\n",
    "    # オートエンコーダモデル (入力から再構築まで)\n",
    "    autoencoder = Model(input_layer, decoded, name=\"autoencoder\")\n",
    "    # エンコーダモデル (入力からボトルネックまで)\n",
    "    encoder = Model(input_layer, encoder_output, name=\"encoder\")\n",
    "\n",
    "    autoencoder.summary()\n",
    "\n",
    "    # --- 5. AEモデルのコンパイルと学習 ---\n",
    "    print(\"\\n--- 5. AEモデルのコンパイルと学習 ---\")\n",
    "    autoencoder.compile(optimizer='adam', loss='mse') # 損失関数は再構築誤差(MSE)\n",
    "\n",
    "    epochs_ae = 50 # AEの学習エポック数 (様子を見て調整)\n",
    "    batch_size_ae = 512\n",
    "\n",
    "    # EarlyStopping: 検証損失(val_loss)が改善しなくなったら停止\n",
    "    early_stopping_ae = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                      patience=5,\n",
    "                                                      mode='min',\n",
    "                                                      restore_best_weights=True)\n",
    "\n",
    "    start_ae_train_time = time.time()\n",
    "    print(\"AE学習中...\")\n",
    "    history_ae = autoencoder.fit(X_train_scaled, X_train_scaled, # 入力と出力(目標)が同じ\n",
    "                                 epochs=epochs_ae,\n",
    "                                 batch_size=batch_size_ae,\n",
    "                                 shuffle=True, # AEの学習ではシャッフルして良い\n",
    "                                 validation_data=(X_test_scaled, X_test_scaled), # テストデータで再構築誤差を評価\n",
    "                                 callbacks=[early_stopping_ae],\n",
    "                                 verbose=1)\n",
    "    end_ae_train_time = time.time()\n",
    "    print(f\"AE学習完了。所要時間: {end_ae_train_time - start_ae_train_time:.2f} 秒\")\n",
    "    print(f\"最終的な検証損失 (Val Loss): {history_ae.history['val_loss'][-1]:.6f}\")\n",
    "\n",
    "    # --- 6. 特徴量の変換 ---\n",
    "    print(\"\\n--- 6. エンコーダによる特徴量変換 ---\")\n",
    "    # 学習済みエンコーダを使って、学習・テストデータを低次元表現に変換\n",
    "    X_train_ae = encoder.predict(X_train_scaled)\n",
    "    X_test_ae = encoder.predict(X_test_scaled)\n",
    "\n",
    "    print(f\"変換後の学習データ形状: {X_train_ae.shape}\") # (サンプル数, encoding_dim)\n",
    "    print(f\"変換後のテストデータ形状: {X_test_ae.shape}\")   # (サンプル数, encoding_dim)\n",
    "    print(\"特徴量変換完了。\")\n",
    "\n",
    "    # これで X_train_ae と X_test_ae が新しい特徴量セットとして準備できました。\n",
    "    # 次のステップで、これらと y_train_b, y_test_b を使って予測モデル(MLPやLightGBM)を学習させます。\n",
    "\n",
    "else:\n",
    "    print(f\"データフレーム df_processed_b_loaded の準備に失敗したか、'{csv_filename}' が見つかりませんでした。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AE特徴量を用いた予測モデル (LightGBM) の学習・評価\n",
    "\n",
    "オートエンコーダによって生成された特徴量 (`X_train_ae`, `X_test_ae`) を使用して、\n",
    "前回チューニングした最適パラメータで LightGBM モデルを学習・評価します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- モデル学習 (AE特徴量 + チューニング済みLGBM) ---\n",
      "使用するパラメータ: {'num_leaves': 183, 'learning_rate': 0.050569794707552296, 'max_depth': 5, 'reg_alpha': 4.462590221186446e-08, 'reg_lambda': 1.4306490938848109e-05, 'colsample_bytree': 0.626063327690084, 'subsample': 0.9387972827397255, 'n_estimators': 237}\n",
      "学習中 (AE特徴量使用)...\n",
      "[LightGBM] [Info] Number of positive: 210247, number of negative: 216557\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005995 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4080\n",
      "[LightGBM] [Info] Number of data points in the train set: 426804, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492608 -> initscore=-0.029571\n",
      "[LightGBM] [Info] Start training from score -0.029571\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "学習完了。所要時間: 0.94 秒\n",
      "\n",
      "--- テストデータでの評価 (AE特徴量 + チューニング済みLGBM) ---\n",
      "テストデータ Accuracy: 0.5120\n",
      "テストデータ AUC Score: 0.5221\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Low (0)       0.51      0.71      0.59     53349\n",
      "    High (1)       0.52      0.32      0.39     53352\n",
      "\n",
      "    accuracy                           0.51    106701\n",
      "   macro avg       0.51      0.51      0.49    106701\n",
      "weighted avg       0.51      0.51      0.49    106701\n",
      "\n",
      "\n",
      "Confusion Matrix:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Low</th>\n",
       "      <th>Predicted High</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Low</th>\n",
       "      <td>37711</td>\n",
       "      <td>15638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual High</th>\n",
       "      <td>36434</td>\n",
       "      <td>16918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted Low  Predicted High\n",
       "Actual Low           37711           15638\n",
       "Actual High          36434           16918"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# AE特徴量 (X_train_ae, X_test_ae) とターゲット (y_train_b, y_test_b) が存在すると仮定\n",
    "# チューニング済みパラメータ best_params_b も存在すると仮定 (前回結果より)\n",
    "if 'X_train_ae' in locals() and 'y_train_b' in locals() and \\\n",
    "   'X_test_ae' in locals() and 'y_test_b' in locals():\n",
    "\n",
    "    # 前回確認した Set B チューニング時の最適パラメータを使用\n",
    "    best_params_b = {'num_leaves': 183, 'learning_rate': 0.050569794707552296, 'max_depth': 5, 'reg_alpha': 4.462590221186446e-08, 'reg_lambda': 1.4306490938848109e-05, 'colsample_bytree': 0.626063327690084, 'subsample': 0.9387972827397255, 'n_estimators': 237}\n",
    "    print(\"--- モデル学習 (AE特徴量 + チューニング済みLGBM) ---\")\n",
    "    print(\"使用するパラメータ:\", best_params_b)\n",
    "\n",
    "    # 最適パラメータでモデルを初期化\n",
    "    model_ae_lgbm = lgb.LGBMClassifier(**best_params_b, random_state=42, n_jobs=-1)\n",
    "\n",
    "    # 学習時間計測\n",
    "    start_train_time = time.time()\n",
    "    print(\"学習中 (AE特徴量使用)...\")\n",
    "    # AE特徴量でフィット\n",
    "    model_ae_lgbm.fit(X_train_ae, y_train_b)\n",
    "    end_train_time = time.time()\n",
    "    print(f\"学習完了。所要時間: {end_train_time - start_train_time:.2f} 秒\")\n",
    "\n",
    "    # --- テストデータでの評価 ---\n",
    "    print(\"\\n--- テストデータでの評価 (AE特徴量 + チューニング済みLGBM) ---\")\n",
    "    y_pred_ae_lgbm = model_ae_lgbm.predict(X_test_ae)\n",
    "    y_pred_proba_ae_lgbm = model_ae_lgbm.predict_proba(X_test_ae)[:, 1]\n",
    "\n",
    "    accuracy_ae_lgbm = accuracy_score(y_test_b, y_pred_ae_lgbm)\n",
    "    auc_ae_lgbm = roc_auc_score(y_test_b, y_pred_proba_ae_lgbm)\n",
    "\n",
    "    print(f\"テストデータ Accuracy: {accuracy_ae_lgbm:.4f}\")\n",
    "    print(f\"テストデータ AUC Score: {auc_ae_lgbm:.4f}\") # ★AE特徴量の効果を見る指標\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test_b, y_pred_ae_lgbm, target_names=['Low (0)', 'High (1)']))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    conf_matrix_ae_lgbm = confusion_matrix(y_test_b, y_pred_ae_lgbm)\n",
    "    conf_matrix_ae_lgbm_df = pd.DataFrame(conf_matrix_ae_lgbm, index=['Actual Low', 'Actual High'], columns=['Predicted Low', 'Predicted High'])\n",
    "    display(conf_matrix_ae_lgbm_df)\n",
    "\n",
    "    # 結果を保存\n",
    "    if 'model_results' not in locals(): model_results = {}\n",
    "    model_results['LGBM_Tuned_on_AE_Features'] = {\n",
    "        'model': model_ae_lgbm,\n",
    "        'auc': auc_ae_lgbm,\n",
    "        'accuracy': accuracy_ae_lgbm,\n",
    "        'y_pred_proba': y_pred_proba_ae_lgbm,\n",
    "        'features': 'Set B -> AE (dim=16)' # 特徴量情報を記録\n",
    "    }\n",
    "\n",
    "else:\n",
    "    print(\"AE特徴量またはターゲットデータが見つかりません。前のステップを実行してください。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AE特徴量を用いた予測モデル (MLP) の学習・評価\n",
    "\n",
    "オートエンコーダによって生成された16次元の特徴量 (`X_train_ae`, `X_test_ae`) を使用して、\n",
    "MLPモデルを学習・評価します。ターゲット変数は元の `y_train_b`, `y_test_b` を使用します。\n",
    "TensorFlow (Keras) が必要です。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "入力特徴量の数 (AE): 16\n",
      "\n",
      "--- MLPモデル定義 (AE特徴量用) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"mlp_on_ae_features\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"mlp_on_ae_features\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m2,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,377</span> (52.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,377\u001b[0m (52.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,961</span> (50.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,961\u001b[0m (50.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">416</span> (1.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m416\u001b[0m (1.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- モデルコンパイル ---\n",
      "\n",
      "--- モデル学習開始 (AE特徴量使用) ---\n",
      "Epoch 1/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5144 - auc: 0.5182 - loss: 0.8611 - val_accuracy: 0.5104 - val_auc: 0.5162 - val_loss: 0.7709\n",
      "Epoch 2/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5280 - auc: 0.5376 - loss: 0.7561 - val_accuracy: 0.5119 - val_auc: 0.5189 - val_loss: 0.7253\n",
      "Epoch 3/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5313 - auc: 0.5435 - loss: 0.7168 - val_accuracy: 0.5154 - val_auc: 0.5238 - val_loss: 0.7056\n",
      "Epoch 4/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5322 - auc: 0.5448 - loss: 0.7008 - val_accuracy: 0.5145 - val_auc: 0.5237 - val_loss: 0.6981\n",
      "Epoch 5/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5321 - auc: 0.5457 - loss: 0.6946 - val_accuracy: 0.5160 - val_auc: 0.5250 - val_loss: 0.6949\n",
      "Epoch 6/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5324 - auc: 0.5467 - loss: 0.6920 - val_accuracy: 0.5156 - val_auc: 0.5243 - val_loss: 0.6936\n",
      "Epoch 7/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5331 - auc: 0.5458 - loss: 0.6911 - val_accuracy: 0.5156 - val_auc: 0.5238 - val_loss: 0.6932\n",
      "Epoch 8/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5335 - auc: 0.5460 - loss: 0.6906 - val_accuracy: 0.5149 - val_auc: 0.5243 - val_loss: 0.6929\n",
      "Epoch 9/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5336 - auc: 0.5461 - loss: 0.6904 - val_accuracy: 0.5132 - val_auc: 0.5220 - val_loss: 0.6930\n",
      "Epoch 10/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5327 - auc: 0.5457 - loss: 0.6904 - val_accuracy: 0.5135 - val_auc: 0.5222 - val_loss: 0.6931\n",
      "Epoch 11/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5334 - auc: 0.5460 - loss: 0.6903 - val_accuracy: 0.5130 - val_auc: 0.5221 - val_loss: 0.6931\n",
      "Epoch 12/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5325 - auc: 0.5460 - loss: 0.6903 - val_accuracy: 0.5151 - val_auc: 0.5230 - val_loss: 0.6928\n",
      "Epoch 13/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5329 - auc: 0.5459 - loss: 0.6903 - val_accuracy: 0.5142 - val_auc: 0.5228 - val_loss: 0.6929\n",
      "Epoch 14/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5329 - auc: 0.5459 - loss: 0.6902 - val_accuracy: 0.5134 - val_auc: 0.5222 - val_loss: 0.6933\n",
      "Epoch 15/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5329 - auc: 0.5459 - loss: 0.6902 - val_accuracy: 0.5132 - val_auc: 0.5222 - val_loss: 0.6933\n",
      "学習完了。所要時間: 22.13 秒\n",
      "\n",
      "--- テストデータでの最終評価 (MLP on AE Features) ---\n",
      "テストデータ Loss: 0.6949\n",
      "テストデータ Accuracy: 0.5160\n",
      "テストデータ AUC Score: 0.5250\n",
      "\n",
      "--- 予測確率の取得 ---\n",
      "\u001b[1m3335/3335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 527us/step\n",
      "予測確率取得完了。\n",
      "\n",
      "Classification Report (閾値0.5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Low (0)       0.51      0.58      0.55     53349\n",
      "    High (1)       0.52      0.45      0.48     53352\n",
      "\n",
      "    accuracy                           0.52    106701\n",
      "   macro avg       0.52      0.52      0.51    106701\n",
      "weighted avg       0.52      0.52      0.51    106701\n",
      "\n",
      "\n",
      "Confusion Matrix (閾値0.5):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Low</th>\n",
       "      <th>Predicted High</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Low</th>\n",
       "      <td>31122</td>\n",
       "      <td>22227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual High</th>\n",
       "      <td>29415</td>\n",
       "      <td>23937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted Low  Predicted High\n",
       "Actual Low           31122           22227\n",
       "Actual High          29415           23937"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "import time\n",
    "\n",
    "# AE特徴量 (X_train_ae, X_test_ae) とターゲット (y_train_b, y_test_b) が存在すると仮定\n",
    "if 'X_train_ae' in locals() and 'y_train_b' in locals() and \\\n",
    "   'X_test_ae' in locals() and 'y_test_b' in locals():\n",
    "\n",
    "    print(f\"入力特徴量の数 (AE): {X_train_ae.shape[1]}\")\n",
    "\n",
    "    # --- MLPモデルの定義 (前回と同様の構造、入力次元のみ変更) ---\n",
    "    print(\"\\n--- MLPモデル定義 (AE特徴量用) ---\")\n",
    "    n_ae_features = X_train_ae.shape[1] # AE特徴量の次元数 (16)\n",
    "    tf.random.set_seed(42) # 再現性のため乱数シード固定\n",
    "\n",
    "    # スケーリングはAE学習前に行っているので、AE特徴量には不要な場合が多い\n",
    "    # 必要であれば再度スケーリングを検討\n",
    "    # scaler_mlp_ae = StandardScaler()\n",
    "    # X_train_ae_scaled = scaler_mlp_ae.fit_transform(X_train_ae)\n",
    "    # X_test_ae_scaled = scaler_mlp_ae.transform(X_test_ae)\n",
    "    # 使用するデータはスケーリング済みとする (AEへの入力がスケーリング済みだったため)\n",
    "    X_train_input = X_train_ae\n",
    "    X_test_input = X_test_ae\n",
    "\n",
    "\n",
    "    model_mlp_ae = keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=(n_ae_features,)), # 入力次元をAE特徴量の次元に合わせる\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(128, activation=\"swish\", kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(64, activation=\"swish\", kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "            layers.Dropout(0.2),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(32, activation=\"swish\", kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "            layers.Dropout(0.1),\n",
    "            layers.Dense(1, activation=\"sigmoid\"),\n",
    "        ],\n",
    "        name=\"mlp_on_ae_features\",\n",
    "    )\n",
    "    model_mlp_ae.summary()\n",
    "\n",
    "    # --- モデルのコンパイル ---\n",
    "    print(\"\\n--- モデルコンパイル ---\")\n",
    "    model_mlp_ae.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "                         loss=\"binary_crossentropy\",\n",
    "                         metrics=[keras.metrics.AUC(name='auc'), 'accuracy'])\n",
    "\n",
    "    # --- モデルの学習 ---\n",
    "    print(\"\\n--- モデル学習開始 (AE特徴量使用) ---\")\n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_auc', patience=10, mode='max', restore_best_weights=True)\n",
    "    epochs = 100\n",
    "    batch_size = 2048 # 前回と同じバッチサイズ\n",
    "\n",
    "    start_train_time = time.time()\n",
    "    history_mlp_ae = model_mlp_ae.fit(X_train_input, # AE特徴量を使用\n",
    "                                      y_train_b,      # 元のターゲット変数\n",
    "                                      batch_size=batch_size,\n",
    "                                      epochs=epochs,\n",
    "                                      validation_data=(X_test_input, y_test_b), # AE特徴量と元のターゲット\n",
    "                                      callbacks=[early_stopping],\n",
    "                                      verbose=1)\n",
    "    end_train_time = time.time()\n",
    "    print(f\"学習完了。所要時間: {end_train_time - start_train_time:.2f} 秒\")\n",
    "\n",
    "    # --- テストデータでの最終評価 ---\n",
    "    print(\"\\n--- テストデータでの最終評価 (MLP on AE Features) ---\")\n",
    "    loss, auc_final_mlp_ae, accuracy_final_mlp_ae = model_mlp_ae.evaluate(X_test_input, y_test_b, verbose=0)\n",
    "\n",
    "    print(f\"テストデータ Loss: {loss:.4f}\")\n",
    "    print(f\"テストデータ Accuracy: {accuracy_final_mlp_ae:.4f}\")\n",
    "    print(f\"テストデータ AUC Score: {auc_final_mlp_ae:.4f}\") # ★これが MLP on AE の性能\n",
    "\n",
    "    # --- 予測確率の取得 (バックテスト用) ---\n",
    "    print(\"\\n--- 予測確率の取得 ---\")\n",
    "    y_pred_proba_mlp_ae = model_mlp_ae.predict(X_test_input).flatten()\n",
    "    print(\"予測確率取得完了。\")\n",
    "\n",
    "    # (オプション) Classification Report と Confusion Matrix\n",
    "    y_pred_mlp_ae = (y_pred_proba_mlp_ae > 0.5).astype(int)\n",
    "    print(\"\\nClassification Report (閾値0.5):\")\n",
    "    print(classification_report(y_test_b, y_pred_mlp_ae, target_names=['Low (0)', 'High (1)']))\n",
    "    print(\"\\nConfusion Matrix (閾値0.5):\")\n",
    "    conf_matrix_mlp_ae = confusion_matrix(y_test_b, y_pred_mlp_ae)\n",
    "    conf_matrix_mlp_ae_df = pd.DataFrame(conf_matrix_mlp_ae, index=['Actual Low', 'Actual High'], columns=['Predicted Low', 'Predicted High'])\n",
    "    display(conf_matrix_mlp_ae_df)\n",
    "\n",
    "    # 結果を保存\n",
    "    if 'model_results' not in locals(): model_results = {}\n",
    "    model_results['MLP_on_AE_Features'] = {\n",
    "        'model': model_mlp_ae,\n",
    "        'auc': auc_final_mlp_ae,\n",
    "        'accuracy': accuracy_final_mlp_ae,\n",
    "        'y_pred_proba': y_pred_proba_mlp_ae,\n",
    "        'features': 'Set B -> AE (dim=16)'\n",
    "    }\n",
    "    # モデルの保存 (任意)\n",
    "    # model_mlp_ae.save('mlp_model_on_ae_features.keras')\n",
    "\n",
    "else:\n",
    "    print(\"AE特徴量 (`X_train_ae`, `X_test_ae`) またはターゲットデータ (`y_train_b`, `y_test_b`) が見つかりません。\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
