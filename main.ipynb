{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NNアプローチ (Plan B): MLPモデルの実装・評価 (特徴量セットB)\n",
    "\n",
    "Jane Streetコンペの知見に基づき、MLPモデルを試します。\n",
    "特徴量セットBのCSVファイルを読み込み、データを準備して実行します。\n",
    "TensorFlow (Keras) が必要です: pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "\n",
    "# --- 1. データの読み込み ---\n",
    "print(\"--- 1. CSVデータの読み込み ---\")\n",
    "csv_filename = 'BTCUSDT_5m_processed_set_b.csv' # 特徴量セットBを保存したファイル名\n",
    "try:\n",
    "    df_processed_b_loaded = pd.read_csv(csv_filename, index_col='timestamp', parse_dates=True)\n",
    "    print(f\"'{csv_filename}' を読み込みました。\")\n",
    "    df_processed_b_loaded.info(verbose=False, memory_usage='deep')\n",
    "except FileNotFoundError:\n",
    "    print(f\"エラー: ファイル '{csv_filename}' が見つかりません。\")\n",
    "    df_processed_b_loaded = None\n",
    "except Exception as e:\n",
    "    print(f\"CSV読み込み中にエラーが発生しました: {e}\")\n",
    "    df_processed_b_loaded = None\n",
    "\n",
    "# --- 2. データ分割 ---\n",
    "if df_processed_b_loaded is not None and not df_processed_b_loaded.empty:\n",
    "    print(\"\\n--- 2. データ分割 ---\")\n",
    "    # 特徴量とターゲットの指定 (元のOHLCV等は除外)\n",
    "    exclude_cols = ['open', 'high', 'low', 'close', 'volume', 'turnover', 'wclprice', 'target']\n",
    "    features_b = [col for col in df_processed_b_loaded.columns if col not in exclude_cols]\n",
    "    print(f\"使用する特徴量の数: {len(features_b)}\")\n",
    "\n",
    "    X_b = df_processed_b_loaded[features_b]\n",
    "    y_b = df_processed_b_loaded['target']\n",
    "\n",
    "    # 分割 (時系列考慮)\n",
    "    test_size = 0.2\n",
    "    X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(\n",
    "        X_b, y_b, test_size=test_size, shuffle=False\n",
    "    )\n",
    "    print(f\"学習データ数: {len(X_train_b)}, テストデータ数: {len(X_test_b)}\")\n",
    "    print(f\"学習データ期間: {X_train_b.index.min()} ~ {X_train_b.index.max()}\")\n",
    "    print(f\"テストデータ期間: {X_test_b.index.min()} ~ {X_test_b.index.max()}\")\n",
    "\n",
    "    # --- 3. データ準備 (スケーリング) ---\n",
    "    print(\"\\n--- 3. データ準備 (スケーリング) ---\")\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_b)\n",
    "    X_test_scaled = scaler.transform(X_test_b)\n",
    "    print(\"スケーリング完了。\")\n",
    "\n",
    "    # --- 4. MLPモデルの定義 ---\n",
    "    print(\"\\n--- 4. MLPモデル定義 ---\")\n",
    "    n_features = X_train_scaled.shape[1]\n",
    "    tf.random.set_seed(42) # TensorFlowの乱数シード固定\n",
    "\n",
    "    model_mlp = keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=(n_features,)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(128, activation=\"swish\", kernel_regularizer=keras.regularizers.l2(0.001)), # L2正則化追加\n",
    "            layers.Dropout(0.3),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(64, activation=\"swish\", kernel_regularizer=keras.regularizers.l2(0.001)), # L2正則化追加\n",
    "            layers.Dropout(0.2),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(32, activation=\"swish\", kernel_regularizer=keras.regularizers.l2(0.001)), # L2正則化追加\n",
    "            layers.Dropout(0.1),\n",
    "            layers.Dense(1, activation=\"sigmoid\"),\n",
    "        ],\n",
    "        name=\"mlp_set_b\",\n",
    "    )\n",
    "    model_mlp.summary()\n",
    "\n",
    "    # --- 5. モデルのコンパイル ---\n",
    "    print(\"\\n--- 5. モデルコンパイル ---\")\n",
    "    model_mlp.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "                      loss=\"binary_crossentropy\",\n",
    "                      metrics=[keras.metrics.AUC(name='auc'), 'accuracy'])\n",
    "\n",
    "    # --- 6. モデルの学習 ---\n",
    "    print(\"\\n--- 6. モデル学習開始 ---\")\n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_auc', patience=10, mode='max', restore_best_weights=True)\n",
    "    epochs = 100\n",
    "    batch_size = 2048\n",
    "\n",
    "    start_train_time = time.time()\n",
    "    history = model_mlp.fit(X_train_scaled,\n",
    "                            y_train_b,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=epochs,\n",
    "                            validation_data=(X_test_scaled, y_test_b),\n",
    "                            callbacks=[early_stopping],\n",
    "                            verbose=1)\n",
    "    end_train_time = time.time()\n",
    "    print(f\"学習完了。所要時間: {end_train_time - start_train_time:.2f} 秒\")\n",
    "\n",
    "    # --- 7. テストデータでの最終評価 ---\n",
    "    print(\"\\n--- 7. テストデータでの最終評価 ---\")\n",
    "    loss, auc_final_mlp, accuracy_final_mlp = model_mlp.evaluate(X_test_scaled, y_test_b, verbose=0)\n",
    "\n",
    "    print(f\"テストデータ Loss: {loss:.4f}\")\n",
    "    print(f\"テストデータ Accuracy: {accuracy_final_mlp:.4f}\")\n",
    "    print(f\"テストデータ AUC Score: {auc_final_mlp:.4f}\") # ★これがMLPモデルの性能\n",
    "\n",
    "    # --- 8. 予測確率の取得 (バックテスト用) ---\n",
    "    print(\"\\n--- 8. 予測確率の取得 ---\")\n",
    "    y_pred_proba_mlp = model_mlp.predict(X_test_scaled).flatten()\n",
    "    print(\"予測確率取得完了。\")\n",
    "\n",
    "    # (オプション) Classification Report と Confusion Matrix\n",
    "    y_pred_mlp = (y_pred_proba_mlp > 0.5).astype(int)\n",
    "    print(\"\\nClassification Report (閾値0.5):\")\n",
    "    print(classification_report(y_test_b, y_pred_mlp, target_names=['Low (0)', 'High (1)']))\n",
    "    print(\"\\nConfusion Matrix (閾値0.5):\")\n",
    "    conf_matrix_mlp = confusion_matrix(y_test_b, y_pred_mlp)\n",
    "    conf_matrix_mlp_df = pd.DataFrame(conf_matrix_mlp, index=['Actual Low', 'Actual High'], columns=['Predicted Low', 'Predicted High'])\n",
    "    display(conf_matrix_mlp_df)\n",
    "\n",
    "    # 結果を保存\n",
    "    if 'model_results' not in locals(): model_results = {}\n",
    "    model_results['MLP_SetB_Final'] = {\n",
    "        'model': model_mlp,\n",
    "        'auc': auc_final_mlp,\n",
    "        'accuracy': accuracy_final_mlp,\n",
    "        'y_pred_proba': y_pred_proba_mlp,\n",
    "        'features': 'Set B (ADR/PowerX)'\n",
    "    }\n",
    "    # モデルの保存 (任意)\n",
    "    # model_mlp.save('mlp_model_setb_final.keras')\n",
    "\n",
    "else:\n",
    "    print(f\"データフレーム df_processed_b_loaded の準備に失敗したか、'{csv_filename}' が見つかりませんでした。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
