{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NNアプローチ (Plan B): MLPモデルの実装・評価 (特徴量セットB)\n",
    "\n",
    "Jane Streetコンペの知見に基づき、MLPモデルを試します。\n",
    "特徴量セットBのCSVファイルを読み込み、データを準備して実行します。\n",
    "TensorFlow (Keras) が必要です: pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. CSVデータの読み込み ---\n",
      "'BTCUSDT_5m_processed_set_b.csv' を読み込みました。\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 533505 entries, 2020-03-26 03:10:00+00:00 to 2025-04-21 13:50:00+00:00\n",
      "Columns: 67 entries, open to MACDs_12_26_9\n",
      "dtypes: float64(64), int64(3)\n",
      "memory usage: 276.8 MB\n",
      "\n",
      "--- 2. データ分割 ---\n",
      "使用する特徴量の数: 59\n",
      "学習データ数: 426804, テストデータ数: 106701\n",
      "学習データ期間: 2020-03-26 03:10:00+00:00 ~ 2024-04-16 02:05:00+00:00\n",
      "テストデータ期間: 2024-04-16 02:10:00+00:00 ~ 2025-04-21 13:50:00+00:00\n",
      "\n",
      "--- 3. データ準備 (スケーリング) ---\n",
      "スケーリング完了。\n",
      "\n",
      "--- 4. MLPモデル定義 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"mlp_set_b\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"mlp_set_b\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">236</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,680</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m)             │           \u001b[38;5;34m236\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m7,680\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,053</span> (74.43 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,053\u001b[0m (74.43 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,551</span> (72.46 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m18,551\u001b[0m (72.46 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">502</span> (1.96 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m502\u001b[0m (1.96 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 5. モデルコンパイル ---\n",
      "\n",
      "--- 6. モデル学習開始 ---\n",
      "Epoch 1/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5166 - auc: 0.5212 - loss: 0.8909 - val_accuracy: 0.5163 - val_auc: 0.5239 - val_loss: 0.7770\n",
      "Epoch 2/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5326 - auc: 0.5438 - loss: 0.7566 - val_accuracy: 0.5185 - val_auc: 0.5258 - val_loss: 0.7194\n",
      "Epoch 3/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5328 - auc: 0.5463 - loss: 0.7108 - val_accuracy: 0.5161 - val_auc: 0.5265 - val_loss: 0.7008\n",
      "Epoch 4/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5333 - auc: 0.5473 - loss: 0.6966 - val_accuracy: 0.5176 - val_auc: 0.5266 - val_loss: 0.6954\n",
      "Epoch 5/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5348 - auc: 0.5476 - loss: 0.6923 - val_accuracy: 0.5170 - val_auc: 0.5264 - val_loss: 0.6936\n",
      "Epoch 6/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5341 - auc: 0.5473 - loss: 0.6909 - val_accuracy: 0.5164 - val_auc: 0.5264 - val_loss: 0.6932\n",
      "Epoch 7/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5346 - auc: 0.5476 - loss: 0.6904 - val_accuracy: 0.5159 - val_auc: 0.5259 - val_loss: 0.6929\n",
      "Epoch 8/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5337 - auc: 0.5474 - loss: 0.6902 - val_accuracy: 0.5162 - val_auc: 0.5267 - val_loss: 0.6929\n",
      "Epoch 9/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5343 - auc: 0.5476 - loss: 0.6901 - val_accuracy: 0.5168 - val_auc: 0.5265 - val_loss: 0.6929\n",
      "Epoch 10/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5344 - auc: 0.5477 - loss: 0.6901 - val_accuracy: 0.5154 - val_auc: 0.5261 - val_loss: 0.6929\n",
      "Epoch 11/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5336 - auc: 0.5478 - loss: 0.6901 - val_accuracy: 0.5158 - val_auc: 0.5265 - val_loss: 0.6928\n",
      "Epoch 12/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5344 - auc: 0.5478 - loss: 0.6901 - val_accuracy: 0.5167 - val_auc: 0.5263 - val_loss: 0.6929\n",
      "Epoch 13/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5345 - auc: 0.5479 - loss: 0.6900 - val_accuracy: 0.5168 - val_auc: 0.5265 - val_loss: 0.6928\n",
      "Epoch 14/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5341 - auc: 0.5477 - loss: 0.6901 - val_accuracy: 0.5162 - val_auc: 0.5264 - val_loss: 0.6928\n",
      "Epoch 15/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5341 - auc: 0.5479 - loss: 0.6900 - val_accuracy: 0.5159 - val_auc: 0.5262 - val_loss: 0.6927\n",
      "Epoch 16/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5341 - auc: 0.5478 - loss: 0.6901 - val_accuracy: 0.5176 - val_auc: 0.5266 - val_loss: 0.6928\n",
      "Epoch 17/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5341 - auc: 0.5479 - loss: 0.6901 - val_accuracy: 0.5165 - val_auc: 0.5263 - val_loss: 0.6928\n",
      "Epoch 18/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5342 - auc: 0.5480 - loss: 0.6900 - val_accuracy: 0.5164 - val_auc: 0.5264 - val_loss: 0.6930\n",
      "学習完了。所要時間: 27.87 秒\n",
      "\n",
      "--- 7. テストデータでの最終評価 ---\n",
      "テストデータ Loss: 0.6929\n",
      "テストデータ Accuracy: 0.5162\n",
      "テストデータ AUC Score: 0.5267\n",
      "\n",
      "--- 8. 予測確率の取得 ---\n",
      "\u001b[1m3335/3335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 543us/step\n",
      "予測確率取得完了。\n",
      "\n",
      "Classification Report (閾値0.5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Low (0)       0.51      0.58      0.54     53349\n",
      "    High (1)       0.52      0.46      0.49     53352\n",
      "\n",
      "    accuracy                           0.52    106701\n",
      "   macro avg       0.52      0.52      0.51    106701\n",
      "weighted avg       0.52      0.52      0.51    106701\n",
      "\n",
      "\n",
      "Confusion Matrix (閾値0.5):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Low</th>\n",
       "      <th>Predicted High</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Low</th>\n",
       "      <td>30726</td>\n",
       "      <td>22623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual High</th>\n",
       "      <td>28997</td>\n",
       "      <td>24355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted Low  Predicted High\n",
       "Actual Low           30726           22623\n",
       "Actual High          28997           24355"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "\n",
    "# --- 1. データの読み込み ---\n",
    "print(\"--- 1. CSVデータの読み込み ---\")\n",
    "csv_filename = 'BTCUSDT_5m_processed_set_b.csv' # 特徴量セットBを保存したファイル名\n",
    "try:\n",
    "    df_processed_b_loaded = pd.read_csv(csv_filename, index_col='timestamp', parse_dates=True)\n",
    "    print(f\"'{csv_filename}' を読み込みました。\")\n",
    "    df_processed_b_loaded.info(verbose=False, memory_usage='deep')\n",
    "except FileNotFoundError:\n",
    "    print(f\"エラー: ファイル '{csv_filename}' が見つかりません。\")\n",
    "    df_processed_b_loaded = None\n",
    "except Exception as e:\n",
    "    print(f\"CSV読み込み中にエラーが発生しました: {e}\")\n",
    "    df_processed_b_loaded = None\n",
    "\n",
    "# --- 2. データ分割 ---\n",
    "if df_processed_b_loaded is not None and not df_processed_b_loaded.empty:\n",
    "    print(\"\\n--- 2. データ分割 ---\")\n",
    "    # 特徴量とターゲットの指定 (元のOHLCV等は除外)\n",
    "    exclude_cols = ['open', 'high', 'low', 'close', 'volume', 'turnover', 'wclprice', 'target']\n",
    "    features_b = [col for col in df_processed_b_loaded.columns if col not in exclude_cols]\n",
    "    print(f\"使用する特徴量の数: {len(features_b)}\")\n",
    "\n",
    "    X_b = df_processed_b_loaded[features_b]\n",
    "    y_b = df_processed_b_loaded['target']\n",
    "\n",
    "    # 分割 (時系列考慮)\n",
    "    test_size = 0.2\n",
    "    X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(\n",
    "        X_b, y_b, test_size=test_size, shuffle=False\n",
    "    )\n",
    "    print(f\"学習データ数: {len(X_train_b)}, テストデータ数: {len(X_test_b)}\")\n",
    "    print(f\"学習データ期間: {X_train_b.index.min()} ~ {X_train_b.index.max()}\")\n",
    "    print(f\"テストデータ期間: {X_test_b.index.min()} ~ {X_test_b.index.max()}\")\n",
    "\n",
    "    # --- 3. データ準備 (スケーリング) ---\n",
    "    print(\"\\n--- 3. データ準備 (スケーリング) ---\")\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_b)\n",
    "    X_test_scaled = scaler.transform(X_test_b)\n",
    "    print(\"スケーリング完了。\")\n",
    "\n",
    "    # --- 4. MLPモデルの定義 ---\n",
    "    print(\"\\n--- 4. MLPモデル定義 ---\")\n",
    "    n_features = X_train_scaled.shape[1]\n",
    "    tf.random.set_seed(42) # TensorFlowの乱数シード固定\n",
    "\n",
    "    model_mlp = keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=(n_features,)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(128, activation=\"swish\", kernel_regularizer=keras.regularizers.l2(0.001)), # L2正則化追加\n",
    "            layers.Dropout(0.3),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(64, activation=\"swish\", kernel_regularizer=keras.regularizers.l2(0.001)), # L2正則化追加\n",
    "            layers.Dropout(0.2),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(32, activation=\"swish\", kernel_regularizer=keras.regularizers.l2(0.001)), # L2正則化追加\n",
    "            layers.Dropout(0.1),\n",
    "            layers.Dense(1, activation=\"sigmoid\"),\n",
    "        ],\n",
    "        name=\"mlp_set_b\",\n",
    "    )\n",
    "    model_mlp.summary()\n",
    "\n",
    "    # --- 5. モデルのコンパイル ---\n",
    "    print(\"\\n--- 5. モデルコンパイル ---\")\n",
    "    model_mlp.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "                      loss=\"binary_crossentropy\",\n",
    "                      metrics=[keras.metrics.AUC(name='auc'), 'accuracy'])\n",
    "\n",
    "    # --- 6. モデルの学習 ---\n",
    "    print(\"\\n--- 6. モデル学習開始 ---\")\n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_auc', patience=10, mode='max', restore_best_weights=True)\n",
    "    epochs = 100\n",
    "    batch_size = 2048\n",
    "\n",
    "    start_train_time = time.time()\n",
    "    history = model_mlp.fit(X_train_scaled,\n",
    "                            y_train_b,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=epochs,\n",
    "                            validation_data=(X_test_scaled, y_test_b),\n",
    "                            callbacks=[early_stopping],\n",
    "                            verbose=1)\n",
    "    end_train_time = time.time()\n",
    "    print(f\"学習完了。所要時間: {end_train_time - start_train_time:.2f} 秒\")\n",
    "\n",
    "    # --- 7. テストデータでの最終評価 ---\n",
    "    print(\"\\n--- 7. テストデータでの最終評価 ---\")\n",
    "    loss, auc_final_mlp, accuracy_final_mlp = model_mlp.evaluate(X_test_scaled, y_test_b, verbose=0)\n",
    "\n",
    "    print(f\"テストデータ Loss: {loss:.4f}\")\n",
    "    print(f\"テストデータ Accuracy: {accuracy_final_mlp:.4f}\")\n",
    "    print(f\"テストデータ AUC Score: {auc_final_mlp:.4f}\") # ★これがMLPモデルの性能\n",
    "\n",
    "    # --- 8. 予測確率の取得 (バックテスト用) ---\n",
    "    print(\"\\n--- 8. 予測確率の取得 ---\")\n",
    "    y_pred_proba_mlp = model_mlp.predict(X_test_scaled).flatten()\n",
    "    print(\"予測確率取得完了。\")\n",
    "\n",
    "    # (オプション) Classification Report と Confusion Matrix\n",
    "    y_pred_mlp = (y_pred_proba_mlp > 0.5).astype(int)\n",
    "    print(\"\\nClassification Report (閾値0.5):\")\n",
    "    print(classification_report(y_test_b, y_pred_mlp, target_names=['Low (0)', 'High (1)']))\n",
    "    print(\"\\nConfusion Matrix (閾値0.5):\")\n",
    "    conf_matrix_mlp = confusion_matrix(y_test_b, y_pred_mlp)\n",
    "    conf_matrix_mlp_df = pd.DataFrame(conf_matrix_mlp, index=['Actual Low', 'Actual High'], columns=['Predicted Low', 'Predicted High'])\n",
    "    display(conf_matrix_mlp_df)\n",
    "\n",
    "    # 結果を保存\n",
    "    if 'model_results' not in locals(): model_results = {}\n",
    "    model_results['MLP_SetB_Final'] = {\n",
    "        'model': model_mlp,\n",
    "        'auc': auc_final_mlp,\n",
    "        'accuracy': accuracy_final_mlp,\n",
    "        'y_pred_proba': y_pred_proba_mlp,\n",
    "        'features': 'Set B (ADR/PowerX)'\n",
    "    }\n",
    "    # モデルの保存 (任意)\n",
    "    # model_mlp.save('mlp_model_setb_final.keras')\n",
    "\n",
    "else:\n",
    "    print(f\"データフレーム df_processed_b_loaded の準備に失敗したか、'{csv_filename}' が見つかりませんでした。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
