{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 (改訂 v2). ライブラリのインポートと設定 (最大量取得・プログレスバー対応)\n",
    "データ取得上限を増やし、プログレスバー表示のための tqdm をインポートします。\n",
    "tqdm が未インストールの場合: !pip install tqdm\n",
    "`start_date_str` で取得を開始したい最も古い日付を指定します。\n",
    "`max_total_data` で取得するデータ件数の大まかな上限を設定できます（メモリ保護のため）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybotters\n",
    "import pandas as pd\n",
    "import asyncio\n",
    "import time\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import nest_asyncio\n",
    "from tqdm.notebook import tqdm # Jupyter Notebook 用の tqdm をインポート\n",
    "\n",
    "# --- 設定項目 ---\n",
    "target_symbol = 'BTCUSDT'\n",
    "interval = '5'\n",
    "category = 'linear'\n",
    "limit = 1000\n",
    "start_date_str = '2000-01-01' # 取得開始希望日をさらに過去に設定 (例: 2020年)\n",
    "# max_total_data = 1000 # 取得上限を増やす (例: 100万件)\n",
    "max_total_data = None      # または None にしてAPIが提供する限り取得する (メモリ注意)\n",
    "output_filename_full = f'{target_symbol}_{interval}m_data_max.csv' # ファイル名変更\n",
    "\n",
    "# --- 設定項目ここまで ---\n",
    "\n",
    "base_url = 'https://api.bybit.com'\n",
    "start_timestamp_ms = int(datetime.strptime(start_date_str, '%Y-%m-%d').replace(tzinfo=timezone.utc).timestamp() * 1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 (改訂 v2). データ取得・整形関数の定義 (最大量取得・プログレスバー版)\n",
    "指定した開始日まで遡ってデータを取得するよう修正した関数。\n",
    "tqdm を組み込み、進捗を表示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch_bybit_kline_full_tqdm(symbol, interval, category, limit, start_ts_ms, max_data=None):\n",
    "    \"\"\"Bybit V5 APIから指定開始日まで遡ってデータを取得し、DataFrameに整形 (tqdm進捗表示付き)\"\"\"\n",
    "    apis = {}\n",
    "    client = pybotters.Client(apis=apis, base_url=base_url)\n",
    "    endpoint = '/v5/market/kline'\n",
    "\n",
    "    all_data_list = []\n",
    "    current_end_time = int(time.time() * 1000)\n",
    "    total_fetched = 0\n",
    "    request_count = 0\n",
    "    estimated_total_requests = None # 総リクエスト回数の推定値 (任意)\n",
    "\n",
    "    # 大まかな総リクエスト回数を推定する場合（任意、正確ではない）\n",
    "    if max_data:\n",
    "         estimated_total_requests = (max_data // limit) + 1\n",
    "    else:\n",
    "         # 現在から開始日までのおおよその期間を計算して推定 (ざっくり)\n",
    "         try:\n",
    "             duration_days = (datetime.now(timezone.utc) - datetime.fromtimestamp(start_ts_ms / 1000, tz=timezone.utc)).days\n",
    "             estimated_total_requests = (duration_days * 24 * (60 // int(interval)) // limit) + 5 # 余裕を持たせる\n",
    "             print(f\"推定総リクエスト回数 (目安): {estimated_total_requests}\")\n",
    "         except:\n",
    "             pass # 計算失敗しても気にしない\n",
    "\n",
    "    print(f\"データ取得を開始します (開始希望日: {start_date_str})...\")\n",
    "\n",
    "    # tqdmの初期化 (totalが不明な場合もある)\n",
    "    # descで何のプログレスバーか示す, unit='req' で単位をリクエストにする\n",
    "    pbar = tqdm(total=estimated_total_requests, desc=f\"Fetching {symbol}\", unit=\"req\")\n",
    "\n",
    "    while True:\n",
    "        request_count += 1\n",
    "        params = {\n",
    "            'category': category,\n",
    "            'symbol': symbol,\n",
    "            'interval': interval,\n",
    "            'limit': limit,\n",
    "            'end': current_end_time,\n",
    "        }\n",
    "        try:\n",
    "            resp = await client.get(endpoint, params=params)\n",
    "            data = await resp.json()\n",
    "\n",
    "            if data['retCode'] == 0 and data['result'] and data['result']['list']:\n",
    "                kline_list = data['result']['list']\n",
    "                fetched_count = len(kline_list)\n",
    "                total_fetched += fetched_count\n",
    "                oldest_timestamp_in_batch = int(kline_list[-1][0])\n",
    "\n",
    "                # tqdmの進捗を更新 (取得件数も表示させる postifx)\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix(fetched=f\"{total_fetched/1000:.1f}k\", last_dt=f\"{datetime.fromtimestamp(oldest_timestamp_in_batch / 1000, tz=timezone.utc).strftime('%Y-%m-%d')}\")\n",
    "\n",
    "                all_data_list.extend(kline_list)\n",
    "\n",
    "                if oldest_timestamp_in_batch <= start_ts_ms or fetched_count < limit:\n",
    "                    print(\"\\n目標開始日以前のデータに到達、または取得データがlimit未満になったため終了します。\")\n",
    "                    break\n",
    "                if max_data is not None and total_fetched >= max_data:\n",
    "                    print(f\"\\n最大取得件数 ({max_data} 件) に到達したため終了します。\")\n",
    "                    break\n",
    "\n",
    "                current_end_time = oldest_timestamp_in_batch - 1\n",
    "                await asyncio.sleep(0.2) # レートリミット考慮\n",
    "\n",
    "            else:\n",
    "                print(f\"\\nReq {request_count}: データ取得エラーまたはデータがありません。Response: {data}\")\n",
    "                break # ループ終了\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\nReq {request_count}: リクエスト中にエラーが発生しました: {e}\")\n",
    "            await asyncio.sleep(1)\n",
    "            if request_count > 5 and total_fetched == 0:\n",
    "                 print(\"\\n初期のデータ取得でエラーが続いたため中断します。\")\n",
    "                 break\n",
    "            continue\n",
    "\n",
    "    pbar.close() # プログレスバーを閉じる\n",
    "\n",
    "    if not all_data_list:\n",
    "        print(\"有効なデータを取得できませんでした。\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # --- DataFrame変換以降は同じ ---\n",
    "    print(\"\\nDataFrame変換中...\")\n",
    "    df = pd.DataFrame(all_data_list, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume', 'turnover'])\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms', utc=True)\n",
    "    df.set_index('timestamp', inplace=True)\n",
    "    numeric_cols = ['open', 'high', 'low', 'close', 'volume', 'turnover']\n",
    "    df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "    df = df[~df.index.duplicated(keep='first')]\n",
    "    df.sort_index(ascending=True, inplace=True)\n",
    "    df = df[df.index >= pd.Timestamp(start_date_str, tz='UTC')]\n",
    "    print(\"DataFrame変換完了。\")\n",
    "\n",
    "    print(f\"\\nデータ取得完了。合計 {len(df)} 件の一意なデータを取得しました。\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 (改訂 v2). データ取得の実行と結果確認 (最大量取得・プログレスバー版)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最大量のデータ取得処理を開始します...(プログレスバーが表示されます)\n",
      "推定総リクエスト回数 (目安): 2666\n",
      "データ取得を開始します (開始希望日: 2000-01-01)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e1f138db94f45a9926b8a58ae1193c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching BTCUSDT:   0%|          | 0/2666 [00:00<?, ?req/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "目標開始日以前のデータに到達、または取得データがlimit未満になったため終了します。\n",
      "\n",
      "DataFrame変換中...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trow1\\AppData\\Local\\Temp\\ipykernel_69492\\3035594412.py:87: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms', utc=True)\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x0000020105AE4980>\n",
      "Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x0000020105B6C890>, 1020688.9855927)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x0000020105AE4AD0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame変換完了。\n",
      "\n",
      "データ取得完了。合計 533705 件の一意なデータを取得しました。\n",
      "データ取得処理が完了しました。\n",
      "\n",
      "--- 取得データ (最初の5行) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>turnover</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-03-25 10:35:00+00:00</th>\n",
       "      <td>6500.0</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>6.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-25 10:40:00+00:00</th>\n",
       "      <td>6500.0</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>6.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-25 10:45:00+00:00</th>\n",
       "      <td>6500.0</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-25 10:50:00+00:00</th>\n",
       "      <td>6500.0</td>\n",
       "      <td>6588.0</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>6588.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>6.5880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-25 10:55:00+00:00</th>\n",
       "      <td>6588.0</td>\n",
       "      <td>6591.5</td>\n",
       "      <td>6588.0</td>\n",
       "      <td>6591.5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>6.5915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             open    high     low   close  volume  turnover\n",
       "timestamp                                                                  \n",
       "2020-03-25 10:35:00+00:00  6500.0  6500.0  6500.0  6500.0   0.001    6.5000\n",
       "2020-03-25 10:40:00+00:00  6500.0  6500.0  6500.0  6500.0   0.001    6.5000\n",
       "2020-03-25 10:45:00+00:00  6500.0  6500.0  6500.0  6500.0   0.000    0.0000\n",
       "2020-03-25 10:50:00+00:00  6500.0  6588.0  6500.0  6588.0   0.001    6.5880\n",
       "2020-03-25 10:55:00+00:00  6588.0  6591.5  6588.0  6591.5   0.001    6.5915"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 取得データ (最後の5行) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>turnover</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-04-21 13:35:00+00:00</th>\n",
       "      <td>87320.5</td>\n",
       "      <td>87500.0</td>\n",
       "      <td>86884.2</td>\n",
       "      <td>87478.1</td>\n",
       "      <td>1359.941</td>\n",
       "      <td>1.185635e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-21 13:40:00+00:00</th>\n",
       "      <td>87478.1</td>\n",
       "      <td>87570.0</td>\n",
       "      <td>87300.0</td>\n",
       "      <td>87399.2</td>\n",
       "      <td>1245.267</td>\n",
       "      <td>1.088904e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-21 13:45:00+00:00</th>\n",
       "      <td>87399.2</td>\n",
       "      <td>87485.0</td>\n",
       "      <td>87187.9</td>\n",
       "      <td>87447.0</td>\n",
       "      <td>778.859</td>\n",
       "      <td>6.804919e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-21 13:50:00+00:00</th>\n",
       "      <td>87447.0</td>\n",
       "      <td>87478.2</td>\n",
       "      <td>87231.4</td>\n",
       "      <td>87235.9</td>\n",
       "      <td>371.193</td>\n",
       "      <td>3.243191e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-21 13:55:00+00:00</th>\n",
       "      <td>87235.9</td>\n",
       "      <td>87261.6</td>\n",
       "      <td>87008.7</td>\n",
       "      <td>87037.3</td>\n",
       "      <td>477.574</td>\n",
       "      <td>4.159717e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              open     high      low    close    volume  \\\n",
       "timestamp                                                                 \n",
       "2025-04-21 13:35:00+00:00  87320.5  87500.0  86884.2  87478.1  1359.941   \n",
       "2025-04-21 13:40:00+00:00  87478.1  87570.0  87300.0  87399.2  1245.267   \n",
       "2025-04-21 13:45:00+00:00  87399.2  87485.0  87187.9  87447.0   778.859   \n",
       "2025-04-21 13:50:00+00:00  87447.0  87478.2  87231.4  87235.9   371.193   \n",
       "2025-04-21 13:55:00+00:00  87235.9  87261.6  87008.7  87037.3   477.574   \n",
       "\n",
       "                               turnover  \n",
       "timestamp                                \n",
       "2025-04-21 13:35:00+00:00  1.185635e+08  \n",
       "2025-04-21 13:40:00+00:00  1.088904e+08  \n",
       "2025-04-21 13:45:00+00:00  6.804919e+07  \n",
       "2025-04-21 13:50:00+00:00  3.243191e+07  \n",
       "2025-04-21 13:55:00+00:00  4.159717e+07  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- データフレーム情報 ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 533705 entries, 2020-03-25 10:35:00+00:00 to 2025-04-21 13:55:00+00:00\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count   Dtype  \n",
      "---  ------    --------------   -----  \n",
      " 0   open      533705 non-null  float64\n",
      " 1   high      533705 non-null  float64\n",
      " 2   low       533705 non-null  float64\n",
      " 3   close     533705 non-null  float64\n",
      " 4   volume    533705 non-null  float64\n",
      " 5   turnover  533705 non-null  float64\n",
      "dtypes: float64(6)\n",
      "memory usage: 28.5 MB\n",
      "\n",
      "取得期間: 2020-03-25 10:35:00+00:00 ~ 2025-04-21 13:55:00+00:00\n",
      "データ件数: 533705\n",
      "\n",
      "データを 'BTCUSDT_5m_data_max.csv' として保存中...\n",
      "保存完了。\n"
     ]
    }
   ],
   "source": [
    "nest_asyncio.apply() # Jupyter環境用\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        print(\"最大量のデータ取得処理を開始します...(プログレスバーが表示されます)\")\n",
    "        # 関数名を変更したものを呼び出す\n",
    "        df_kline_max = asyncio.run(fetch_bybit_kline_full_tqdm(target_symbol, interval, category, limit, start_timestamp_ms, max_total_data))\n",
    "        print(\"データ取得処理が完了しました。\")\n",
    "    except Exception as e:\n",
    "        print(f\"データ取得中に予期せぬエラーが発生しました: {e}\")\n",
    "        df_kline_max = pd.DataFrame() # エラー時は空のDataFrame\n",
    "\n",
    "# --- 結果表示 (変数名を df_kline_max に変更) ---\n",
    "if not df_kline_max.empty:\n",
    "    print(\"\\n--- 取得データ (最初の5行) ---\")\n",
    "    display(df_kline_max.head())\n",
    "    print(\"\\n--- 取得データ (最後の5行) ---\")\n",
    "    display(df_kline_max.tail())\n",
    "    print(\"\\n--- データフレーム情報 ---\")\n",
    "    df_kline_max.info()\n",
    "    print(f\"\\n取得期間: {df_kline_max.index.min()} ~ {df_kline_max.index.max()}\")\n",
    "    print(f\"データ件数: {len(df_kline_max)}\")\n",
    "\n",
    "    # (任意) 取得したデータを保存\n",
    "    try:\n",
    "        print(f\"\\nデータを '{output_filename_full}' として保存中...\")\n",
    "        df_kline_max.to_csv(output_filename_full)\n",
    "        print(\"保存完了。\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nデータの保存中にエラーが発生しました: {e}\")\n",
    "else:\n",
    "    print(\"\\nデータフレームが空、または取得に失敗しました。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴量セット A (WclPriceベース) の作成\n",
    "\n",
    "Weighted Close (WclPrice) を計算し、主要なテクニカル指標の計算に WclPrice を使用します。\n",
    "tqdm で進捗を表示し、目的変数は時間差チェック済みのものを利用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特徴量セット A (WclPriceベース) の作成を開始します...\n",
      "Calculating WclPrice...\n",
      "テクニカル指標 (WclPriceベース) を計算中...\n",
      "Calculating MAs (WclPrice)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "969f4f278a6440f4999624757522a097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MAs_WCL:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating MACD (WclPrice)...\n",
      "Calculating RSI (WclPrice)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "419802c0cc3b4a178af2a252fe704a52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RSI_WCL:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Stochastics...\n",
      "Calculating StochRSI (Close base)...\n",
      "Calculating Bollinger Bands (WclPrice)...\n",
      "Calculating ATR...\n",
      "Calculating ADX...\n",
      "Calculating CCI (HLC base)...\n",
      "Calculating Williams %R...\n",
      "Calculating OBV...\n",
      "ラグ特徴量を計算中...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed9f389358d4430b08a77a38ea2c325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Returns:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "時間特徴量を計算中...\n",
      "目的変数 (ターゲット) を作成中 (5分間隔チェック付き)...\n",
      "\n",
      "NaN削除前の行数: 533705\n",
      "NaN削除処理を開始します...\n",
      "NaN削除処理完了。\n",
      "NaN削除後の行数: 533505\n",
      "削除された行数: 200\n",
      "\n",
      "--- 特徴量セット A (WclPrice) 作成完了 ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 533505 entries, 2020-03-26 03:10:00+00:00 to 2025-04-21 13:50:00+00:00\n",
      "Columns: 62 entries, open to target\n",
      "dtypes: float64(59), int32(2), int64(1)\n",
      "memory usage: 252.4 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trow1\\AppData\\Local\\Temp\\ipykernel_69492\\2216702590.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_processed_wcl['target'] = df_processed_wcl['target'].astype(int)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>turnover</th>\n",
       "      <th>wclprice</th>\n",
       "      <th>open_norm_wcl</th>\n",
       "      <th>high_norm_wcl</th>\n",
       "      <th>low_norm_wcl</th>\n",
       "      <th>...</th>\n",
       "      <th>return_5_wcl</th>\n",
       "      <th>return_10</th>\n",
       "      <th>return_10_wcl</th>\n",
       "      <th>return_20</th>\n",
       "      <th>return_20_wcl</th>\n",
       "      <th>return_50</th>\n",
       "      <th>return_50_wcl</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-03-26 03:10:00+00:00</th>\n",
       "      <td>6687.5</td>\n",
       "      <td>6687.5</td>\n",
       "      <td>6667.5</td>\n",
       "      <td>6670.0</td>\n",
       "      <td>35.519</td>\n",
       "      <td>236911.730</td>\n",
       "      <td>6673.750</td>\n",
       "      <td>1.002060</td>\n",
       "      <td>1.002060</td>\n",
       "      <td>0.999063</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001944</td>\n",
       "      <td>-0.000450</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>-0.005517</td>\n",
       "      <td>-0.004475</td>\n",
       "      <td>-0.001048</td>\n",
       "      <td>-0.000636</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-26 03:15:00+00:00</th>\n",
       "      <td>6670.0</td>\n",
       "      <td>6693.5</td>\n",
       "      <td>6670.0</td>\n",
       "      <td>6693.5</td>\n",
       "      <td>92.544</td>\n",
       "      <td>619443.264</td>\n",
       "      <td>6687.625</td>\n",
       "      <td>0.997365</td>\n",
       "      <td>1.000878</td>\n",
       "      <td>0.997365</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000766</td>\n",
       "      <td>0.004728</td>\n",
       "      <td>0.003432</td>\n",
       "      <td>-0.001864</td>\n",
       "      <td>-0.002424</td>\n",
       "      <td>0.003598</td>\n",
       "      <td>0.002567</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-26 03:20:00+00:00</th>\n",
       "      <td>6693.5</td>\n",
       "      <td>6693.5</td>\n",
       "      <td>6682.5</td>\n",
       "      <td>6682.5</td>\n",
       "      <td>10.882</td>\n",
       "      <td>72718.965</td>\n",
       "      <td>6685.250</td>\n",
       "      <td>1.001234</td>\n",
       "      <td>1.001234</td>\n",
       "      <td>0.999589</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001307</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>-0.004840</td>\n",
       "      <td>-0.003707</td>\n",
       "      <td>0.004283</td>\n",
       "      <td>0.004112</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-26 03:25:00+00:00</th>\n",
       "      <td>6682.5</td>\n",
       "      <td>6694.0</td>\n",
       "      <td>6682.5</td>\n",
       "      <td>6685.0</td>\n",
       "      <td>11.240</td>\n",
       "      <td>75139.400</td>\n",
       "      <td>6686.625</td>\n",
       "      <td>0.999383</td>\n",
       "      <td>1.001103</td>\n",
       "      <td>0.999383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.001085</td>\n",
       "      <td>-0.003057</td>\n",
       "      <td>-0.003168</td>\n",
       "      <td>0.003528</td>\n",
       "      <td>0.004054</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-26 03:30:00+00:00</th>\n",
       "      <td>6685.0</td>\n",
       "      <td>6738.0</td>\n",
       "      <td>6685.0</td>\n",
       "      <td>6737.5</td>\n",
       "      <td>13.516</td>\n",
       "      <td>91064.050</td>\n",
       "      <td>6724.500</td>\n",
       "      <td>0.994126</td>\n",
       "      <td>1.002008</td>\n",
       "      <td>0.994126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005928</td>\n",
       "      <td>0.008608</td>\n",
       "      <td>0.006662</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>0.004575</td>\n",
       "      <td>0.010120</td>\n",
       "      <td>0.008492</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             open    high     low   close  volume    turnover  \\\n",
       "timestamp                                                                       \n",
       "2020-03-26 03:10:00+00:00  6687.5  6687.5  6667.5  6670.0  35.519  236911.730   \n",
       "2020-03-26 03:15:00+00:00  6670.0  6693.5  6670.0  6693.5  92.544  619443.264   \n",
       "2020-03-26 03:20:00+00:00  6693.5  6693.5  6682.5  6682.5  10.882   72718.965   \n",
       "2020-03-26 03:25:00+00:00  6682.5  6694.0  6682.5  6685.0  11.240   75139.400   \n",
       "2020-03-26 03:30:00+00:00  6685.0  6738.0  6685.0  6737.5  13.516   91064.050   \n",
       "\n",
       "                           wclprice  open_norm_wcl  high_norm_wcl  \\\n",
       "timestamp                                                           \n",
       "2020-03-26 03:10:00+00:00  6673.750       1.002060       1.002060   \n",
       "2020-03-26 03:15:00+00:00  6687.625       0.997365       1.000878   \n",
       "2020-03-26 03:20:00+00:00  6685.250       1.001234       1.001234   \n",
       "2020-03-26 03:25:00+00:00  6686.625       0.999383       1.001103   \n",
       "2020-03-26 03:30:00+00:00  6724.500       0.994126       1.002008   \n",
       "\n",
       "                           low_norm_wcl  ...  return_5_wcl  return_10  \\\n",
       "timestamp                                ...                            \n",
       "2020-03-26 03:10:00+00:00      0.999063  ...     -0.001944  -0.000450   \n",
       "2020-03-26 03:15:00+00:00      0.997365  ...     -0.000766   0.004728   \n",
       "2020-03-26 03:20:00+00:00      0.999589  ...     -0.001307   0.000749   \n",
       "2020-03-26 03:25:00+00:00      0.999383  ...      0.000355   0.000749   \n",
       "2020-03-26 03:30:00+00:00      0.994126  ...      0.005928   0.008608   \n",
       "\n",
       "                           return_10_wcl  return_20  return_20_wcl  return_50  \\\n",
       "timestamp                                                                       \n",
       "2020-03-26 03:10:00+00:00       0.000300  -0.005517      -0.004475  -0.001048   \n",
       "2020-03-26 03:15:00+00:00       0.003432  -0.001864      -0.002424   0.003598   \n",
       "2020-03-26 03:20:00+00:00       0.002005  -0.004840      -0.003707   0.004283   \n",
       "2020-03-26 03:25:00+00:00       0.001085  -0.003057      -0.003168   0.003528   \n",
       "2020-03-26 03:30:00+00:00       0.006662   0.007100       0.004575   0.010120   \n",
       "\n",
       "                           return_50_wcl  hour  dayofweek  target  \n",
       "timestamp                                                          \n",
       "2020-03-26 03:10:00+00:00      -0.000636     3          3       1  \n",
       "2020-03-26 03:15:00+00:00       0.002567     3          3       0  \n",
       "2020-03-26 03:20:00+00:00       0.004112     3          3       1  \n",
       "2020-03-26 03:25:00+00:00       0.004054     3          3       1  \n",
       "2020-03-26 03:30:00+00:00       0.008492     3          3       0  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# df_kline_max (最大量データ) がロード済みとする\n",
    "if 'df_kline_max' in locals() and not df_kline_max.empty:\n",
    "    print(\"特徴量セット A (WclPriceベース) の作成を開始します...\")\n",
    "    df_features_wcl = df_kline_max.copy()\n",
    "\n",
    "    # 1. Weighted Close (WclPrice) の計算\n",
    "    print(\"Calculating WclPrice...\")\n",
    "    df_features_wcl['wclprice'] = (df_features_wcl['high'] + df_features_wcl['low'] + 2 * df_features_wcl['close']) / 4\n",
    "\n",
    "    # --- 特徴量計算 (WclPrice を入力に使用) ---\n",
    "    # 2. 基本的な価格特徴量 (WclPrice基準) - オプション\n",
    "    df_features_wcl['open_norm_wcl'] = df_features_wcl['open'] / df_features_wcl['wclprice']\n",
    "    df_features_wcl['high_norm_wcl'] = df_features_wcl['high'] / df_features_wcl['wclprice']\n",
    "    df_features_wcl['low_norm_wcl'] = df_features_wcl['low'] / df_features_wcl['wclprice']\n",
    "    df_features_wcl['close_norm_wcl'] = df_features_wcl['close'] / df_features_wcl['wclprice']\n",
    "\n",
    "    # 3. テクニカル指標 (入力に 'wclprice' を指定)\n",
    "    print(\"テクニカル指標 (WclPriceベース) を計算中...\")\n",
    "    periods_ma = [7, 14, 21, 50, 100, 200]\n",
    "    print(\"Calculating MAs (WclPrice)...\")\n",
    "    for length in tqdm(periods_ma, desc=\"MAs_WCL\"):\n",
    "        # pandas-ta で入力列を指定するには close='wclprice' のように引数を渡す\n",
    "        df_features_wcl.ta.sma(close=df_features_wcl['wclprice'], length=length, append=True, col_names=(f'SMA_{length}_WCL'))\n",
    "        df_features_wcl.ta.ema(close=df_features_wcl['wclprice'], length=length, append=True, col_names=(f'EMA_{length}_WCL'))\n",
    "\n",
    "    print(\"Calculating MACD (WclPrice)...\")\n",
    "    df_features_wcl.ta.macd(close=df_features_wcl['wclprice'], append=True, col_names=('MACD_WCL', 'MACDh_WCL', 'MACDs_WCL')) # 列名を変更\n",
    "\n",
    "    periods_rsi = [7, 14, 21]\n",
    "    print(\"Calculating RSI (WclPrice)...\")\n",
    "    for length in tqdm(periods_rsi, desc=\"RSI_WCL\"):\n",
    "         df_features_wcl.ta.rsi(close=df_features_wcl['wclprice'], length=length, append=True, col_names=(f'RSI_{length}_WCL'))\n",
    "\n",
    "    # Stochastics は High, Low, Close を使うので WclPrice ではなく通常通り計算\n",
    "    print(\"Calculating Stochastics...\")\n",
    "    df_features_wcl.ta.stoch(append=True) # STOCHk_14_3_3, STOCHd_14_3_3\n",
    "\n",
    "    # StochRSI は RSI に基づくので、WclPrice ベースの RSI を使うか検討 -> ここでは Close ベースの RSI を使う StochRSI を計算\n",
    "    print(\"Calculating StochRSI (Close base)...\")\n",
    "    df_features_wcl.ta.stochrsi(append=True) # STOCHRSIk_14_14_3_3, STOCHRSId_14_14_3_3\n",
    "\n",
    "    # Bollinger Bands (WclPrice ベース)\n",
    "    print(\"Calculating Bollinger Bands (WclPrice)...\")\n",
    "    df_features_wcl.ta.bbands(close=df_features_wcl['wclprice'], length=20, std=2, append=True, col_names=('BBL_WCL', 'BBM_WCL', 'BBU_WCL', 'BBB_WCL', 'BBP_WCL')) # 列名変更\n",
    "\n",
    "    # ATR (通常通り H, L, C を使う)\n",
    "    print(\"Calculating ATR...\")\n",
    "    df_features_wcl.ta.atr(length=14, append=True, col_names=('ATR_14'))\n",
    "\n",
    "    # ADX (通常通り H, L, C を使う)\n",
    "    print(\"Calculating ADX...\")\n",
    "    df_features_wcl.ta.adx(length=14, append=True) # ADX_14, DMP_14, DMN_14\n",
    "\n",
    "    # CCI (WclPrice ベースで計算可能か？ -> HLC を使うのが一般的) -> 通常通り計算\n",
    "    print(\"Calculating CCI (HLC base)...\")\n",
    "    df_features_wcl.ta.cci(length=14, append=True, col_names=('CCI_14'))\n",
    "\n",
    "    # Williams %R (通常通り H, L, C を使う)\n",
    "    print(\"Calculating Williams %R...\")\n",
    "    df_features_wcl.ta.willr(length=14, append=True, col_names=('WILLR_14'))\n",
    "\n",
    "    # OBV (通常通り C, V を使う)\n",
    "    print(\"Calculating OBV...\")\n",
    "    df_features_wcl.ta.obv(append=True)\n",
    "\n",
    "    # --- 4. ラグ特徴量 (WclPrice と Close の両方) ---\n",
    "    print(\"ラグ特徴量を計算中...\")\n",
    "    periods_return = [1, 2, 3, 5, 10, 20, 50]\n",
    "    for n in tqdm(periods_return, desc=\"Returns\"):\n",
    "        df_features_wcl[f'return_{n}'] = df_features_wcl['close'].pct_change(periods=n)\n",
    "        df_features_wcl[f'return_{n}_wcl'] = df_features_wcl['wclprice'].pct_change(periods=n) # WclPriceのリターンも追加\n",
    "\n",
    "    # --- 5. 時間特徴量 ---\n",
    "    print(\"時間特徴量を計算中...\")\n",
    "    df_features_wcl['hour'] = df_features_wcl.index.hour\n",
    "    df_features_wcl['dayofweek'] = df_features_wcl.index.dayofweek\n",
    "\n",
    "    # --- 6. 目的変数作成 (時間差チェック付き) ---\n",
    "    print(\"目的変数 (ターゲット) を作成中 (5分間隔チェック付き)...\")\n",
    "    df_features_wcl['timediff'] = df_features_wcl.index.to_series().diff()\n",
    "    df_features_wcl['next_close'] = df_features_wcl['close'].shift(-1)\n",
    "    df_features_wcl['next_timediff'] = df_features_wcl['timediff'].shift(-1)\n",
    "    condition_high = (df_features_wcl['next_close'] > df_features_wcl['close']) & (df_features_wcl['next_timediff'] == pd.Timedelta('5 minutes'))\n",
    "    condition_low = (df_features_wcl['next_close'] <= df_features_wcl['close']) & (df_features_wcl['next_timediff'] == pd.Timedelta('5 minutes'))\n",
    "    df_features_wcl['target'] = np.select([condition_high, condition_low], [1.0, 0.0], default=np.nan)\n",
    "    df_features_wcl = df_features_wcl.drop(columns=['timediff', 'next_timediff', 'next_close'])\n",
    "\n",
    "    # --- 7. NaN削除 ---\n",
    "    rows_before_dropna = len(df_features_wcl)\n",
    "    print(f\"\\nNaN削除前の行数: {rows_before_dropna}\")\n",
    "    print(\"NaN削除処理を開始します...\")\n",
    "    df_processed_wcl = df_features_wcl.dropna()\n",
    "    print(\"NaN削除処理完了。\")\n",
    "    rows_after_dropna = len(df_processed_wcl)\n",
    "    if 'target' in df_processed_wcl.columns:\n",
    "         df_processed_wcl['target'] = df_processed_wcl['target'].astype(int)\n",
    "\n",
    "    print(f\"NaN削除後の行数: {rows_after_dropna}\")\n",
    "    print(f\"削除された行数: {rows_before_dropna - rows_after_dropna}\")\n",
    "\n",
    "    print(\"\\n--- 特徴量セット A (WclPrice) 作成完了 ---\")\n",
    "    df_processed_wcl.info(verbose=False, memory_usage='deep')\n",
    "    display(df_processed_wcl.head())\n",
    "\n",
    "    # (任意) 保存\n",
    "    df_processed_wcl.to_csv('processed_data_wcl.csv')\n",
    "\n",
    "else:\n",
    "    print(\"df_kline_max が存在しないか空です。データ取得ステップを先に実行してください。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴量セット B (ADR/PowerX要素追加) の作成\n",
    "\n",
    "特徴量セットA (WclPriceベース、NaN削除前) に、ATR(7) と PowerX戦略で使われる指標パラメータ (Closeベース) を追加します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特徴量セット B (ADR/PowerX要素追加) の作成を開始します...\n",
      "Calculating ATR(7)...\n",
      "Calculating RSI(7) - Close base...\n",
      "Stochastics(14,3,3) - Close base already exists.\n",
      "Calculating MACD(12,26,9) - Close base...\n",
      "Target variable already exists (incl. NaNs from time check).\n",
      "\n",
      "NaN削除前の行数 (Set B): 533705\n",
      "NaN削除処理を開始します...\n",
      "NaN削除処理完了。\n",
      "NaN削除後の行数 (Set B): 533505\n",
      "削除された行数: 200\n",
      "\n",
      "--- 特徴量セット B (ADR/PowerX追加) 作成完了 ---\n",
      "最終的な特徴量の数: 66\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 533505 entries, 2020-03-26 03:10:00+00:00 to 2025-04-21 13:50:00+00:00\n",
      "Columns: 67 entries, open to MACDs_12_26_9\n",
      "dtypes: float64(64), int32(2), int64(1)\n",
      "memory usage: 272.7 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trow1\\AppData\\Local\\Temp\\ipykernel_69492\\517799482.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_processed_b['target'] = df_processed_b['target'].astype(int)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>turnover</th>\n",
       "      <th>wclprice</th>\n",
       "      <th>open_norm_wcl</th>\n",
       "      <th>high_norm_wcl</th>\n",
       "      <th>low_norm_wcl</th>\n",
       "      <th>...</th>\n",
       "      <th>return_50</th>\n",
       "      <th>return_50_wcl</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>target</th>\n",
       "      <th>ATR_7</th>\n",
       "      <th>RSI_7</th>\n",
       "      <th>MACD_12_26_9</th>\n",
       "      <th>MACDh_12_26_9</th>\n",
       "      <th>MACDs_12_26_9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-03-26 03:10:00+00:00</th>\n",
       "      <td>6687.5</td>\n",
       "      <td>6687.5</td>\n",
       "      <td>6667.5</td>\n",
       "      <td>6670.0</td>\n",
       "      <td>35.519</td>\n",
       "      <td>236911.730</td>\n",
       "      <td>6673.750</td>\n",
       "      <td>1.002060</td>\n",
       "      <td>1.002060</td>\n",
       "      <td>0.999063</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001048</td>\n",
       "      <td>-0.000636</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>11.074765</td>\n",
       "      <td>36.876388</td>\n",
       "      <td>-4.335085</td>\n",
       "      <td>-0.096776</td>\n",
       "      <td>-4.238309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-26 03:15:00+00:00</th>\n",
       "      <td>6670.0</td>\n",
       "      <td>6693.5</td>\n",
       "      <td>6670.0</td>\n",
       "      <td>6693.5</td>\n",
       "      <td>92.544</td>\n",
       "      <td>619443.264</td>\n",
       "      <td>6687.625</td>\n",
       "      <td>0.997365</td>\n",
       "      <td>1.000878</td>\n",
       "      <td>0.997365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003598</td>\n",
       "      <td>0.002567</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>12.849799</td>\n",
       "      <td>56.430949</td>\n",
       "      <td>-3.205570</td>\n",
       "      <td>0.826191</td>\n",
       "      <td>-4.031761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-26 03:20:00+00:00</th>\n",
       "      <td>6693.5</td>\n",
       "      <td>6693.5</td>\n",
       "      <td>6682.5</td>\n",
       "      <td>6682.5</td>\n",
       "      <td>10.882</td>\n",
       "      <td>72718.965</td>\n",
       "      <td>6685.250</td>\n",
       "      <td>1.001234</td>\n",
       "      <td>1.001234</td>\n",
       "      <td>0.999589</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004283</td>\n",
       "      <td>0.004112</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>12.585542</td>\n",
       "      <td>48.265748</td>\n",
       "      <td>-3.161585</td>\n",
       "      <td>0.696141</td>\n",
       "      <td>-3.857726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-26 03:25:00+00:00</th>\n",
       "      <td>6682.5</td>\n",
       "      <td>6694.0</td>\n",
       "      <td>6682.5</td>\n",
       "      <td>6685.0</td>\n",
       "      <td>11.240</td>\n",
       "      <td>75139.400</td>\n",
       "      <td>6686.625</td>\n",
       "      <td>0.999383</td>\n",
       "      <td>1.001103</td>\n",
       "      <td>0.999383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003528</td>\n",
       "      <td>0.004054</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>12.430464</td>\n",
       "      <td>50.177236</td>\n",
       "      <td>-2.891664</td>\n",
       "      <td>0.772850</td>\n",
       "      <td>-3.664514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-26 03:30:00+00:00</th>\n",
       "      <td>6685.0</td>\n",
       "      <td>6738.0</td>\n",
       "      <td>6685.0</td>\n",
       "      <td>6737.5</td>\n",
       "      <td>13.516</td>\n",
       "      <td>91064.050</td>\n",
       "      <td>6724.500</td>\n",
       "      <td>0.994126</td>\n",
       "      <td>1.002008</td>\n",
       "      <td>0.994126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010120</td>\n",
       "      <td>0.008492</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>18.226112</td>\n",
       "      <td>73.849488</td>\n",
       "      <td>1.540800</td>\n",
       "      <td>4.164251</td>\n",
       "      <td>-2.623451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             open    high     low   close  volume    turnover  \\\n",
       "timestamp                                                                       \n",
       "2020-03-26 03:10:00+00:00  6687.5  6687.5  6667.5  6670.0  35.519  236911.730   \n",
       "2020-03-26 03:15:00+00:00  6670.0  6693.5  6670.0  6693.5  92.544  619443.264   \n",
       "2020-03-26 03:20:00+00:00  6693.5  6693.5  6682.5  6682.5  10.882   72718.965   \n",
       "2020-03-26 03:25:00+00:00  6682.5  6694.0  6682.5  6685.0  11.240   75139.400   \n",
       "2020-03-26 03:30:00+00:00  6685.0  6738.0  6685.0  6737.5  13.516   91064.050   \n",
       "\n",
       "                           wclprice  open_norm_wcl  high_norm_wcl  \\\n",
       "timestamp                                                           \n",
       "2020-03-26 03:10:00+00:00  6673.750       1.002060       1.002060   \n",
       "2020-03-26 03:15:00+00:00  6687.625       0.997365       1.000878   \n",
       "2020-03-26 03:20:00+00:00  6685.250       1.001234       1.001234   \n",
       "2020-03-26 03:25:00+00:00  6686.625       0.999383       1.001103   \n",
       "2020-03-26 03:30:00+00:00  6724.500       0.994126       1.002008   \n",
       "\n",
       "                           low_norm_wcl  ...  return_50  return_50_wcl  hour  \\\n",
       "timestamp                                ...                                   \n",
       "2020-03-26 03:10:00+00:00      0.999063  ...  -0.001048      -0.000636     3   \n",
       "2020-03-26 03:15:00+00:00      0.997365  ...   0.003598       0.002567     3   \n",
       "2020-03-26 03:20:00+00:00      0.999589  ...   0.004283       0.004112     3   \n",
       "2020-03-26 03:25:00+00:00      0.999383  ...   0.003528       0.004054     3   \n",
       "2020-03-26 03:30:00+00:00      0.994126  ...   0.010120       0.008492     3   \n",
       "\n",
       "                           dayofweek  target      ATR_7      RSI_7  \\\n",
       "timestamp                                                            \n",
       "2020-03-26 03:10:00+00:00          3       1  11.074765  36.876388   \n",
       "2020-03-26 03:15:00+00:00          3       0  12.849799  56.430949   \n",
       "2020-03-26 03:20:00+00:00          3       1  12.585542  48.265748   \n",
       "2020-03-26 03:25:00+00:00          3       1  12.430464  50.177236   \n",
       "2020-03-26 03:30:00+00:00          3       0  18.226112  73.849488   \n",
       "\n",
       "                           MACD_12_26_9  MACDh_12_26_9  MACDs_12_26_9  \n",
       "timestamp                                                              \n",
       "2020-03-26 03:10:00+00:00     -4.335085      -0.096776      -4.238309  \n",
       "2020-03-26 03:15:00+00:00     -3.205570       0.826191      -4.031761  \n",
       "2020-03-26 03:20:00+00:00     -3.161585       0.696141      -3.857726  \n",
       "2020-03-26 03:25:00+00:00     -2.891664       0.772850      -3.664514  \n",
       "2020-03-26 03:30:00+00:00      1.540800       4.164251      -2.623451  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "処理済みデータを BTCUSDT_5m_processed_set_b.csv として保存中...\n",
      "保存完了。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# 前のステップで作成した df_features_wcl (特徴量セットA、NaN削除前) が存在すると仮定\n",
    "if 'df_features_wcl' in locals() and not df_features_wcl.empty:\n",
    "    print(\"特徴量セット B (ADR/PowerX要素追加) の作成を開始します...\")\n",
    "    # Set A (NaN削除前) をコピーして開始\n",
    "    df_features_b = df_features_wcl.copy()\n",
    "\n",
    "    # --- ADR (ATRで代用) の追加 ---\n",
    "    print(\"Calculating ATR(7)...\")\n",
    "    # ATRは High, Low, Close を使う\n",
    "    # length=7 を指定\n",
    "    df_features_b.ta.atr(length=7, append=True, col_names=('ATR_7'))\n",
    "\n",
    "    # --- PowerX 指標パラメータの確認・追加 (Closeベース) ---\n",
    "    # RSI(7) - Closeベース\n",
    "    if 'RSI_7' not in df_features_b.columns: # CloseベースのRSI(7)がなければ追加\n",
    "        print(\"Calculating RSI(7) - Close base...\")\n",
    "        df_features_b.ta.rsi(length=7, append=True, col_names=('RSI_7'))\n",
    "    else:\n",
    "        print(\"RSI(7) - Close base already exists.\")\n",
    "\n",
    "    # Stochastics(14, 3, 3) - Closeベース (通常はこちらがデフォルトのはず)\n",
    "    # Set A 作成時に追加済みのはずなので確認のみ\n",
    "    if 'STOCHk_14_3_3' in df_features_b.columns and 'STOCHd_14_3_3' in df_features_b.columns:\n",
    "        print(\"Stochastics(14,3,3) - Close base already exists.\")\n",
    "    else:\n",
    "        print(\"Warning: Stochastics(14,3,3) not found, consider adding it based on Close.\")\n",
    "        # df_features_b.ta.stoch(k=14, d=3, smooth_k=3, append=True) # 必要なら追加\n",
    "\n",
    "    # MACD(12, 26, 9) - Closeベース\n",
    "    if 'MACD_12_26_9' not in df_features_b.columns: # CloseベースのMACDがなければ追加\n",
    "         print(\"Calculating MACD(12,26,9) - Close base...\")\n",
    "         # pandas-ta のデフォルトが (12, 26, 9) なので、引数なしでも良いはず\n",
    "         df_features_b.ta.macd(append=True) # これで MACD_12_26_9, MACDh_12_26_9, MACDs_12_26_9 が追加されるはず\n",
    "    else:\n",
    "         print(\"MACD(12,26,9) - Close base already exists.\")\n",
    "\n",
    "    # --- 目的変数作成 (変更なし) ---\n",
    "    # target 列は df_features_wcl に既に存在し、NaNが含まれているはず\n",
    "    print(\"Target variable already exists (incl. NaNs from time check).\")\n",
    "\n",
    "\n",
    "    # --- NaN削除 ---\n",
    "    rows_before_dropna_b = len(df_features_b)\n",
    "    print(f\"\\nNaN削除前の行数 (Set B): {rows_before_dropna_b}\")\n",
    "    print(\"NaN削除処理を開始します...\")\n",
    "    # 追加した指標によって NaN が発生する行が増える可能性がある\n",
    "    df_processed_b = df_features_b.dropna()\n",
    "    print(\"NaN削除処理完了。\")\n",
    "    rows_after_dropna_b = len(df_processed_b)\n",
    "    if 'target' in df_processed_b.columns:\n",
    "         # target列を整数型に変換\n",
    "         df_processed_b['target'] = df_processed_b['target'].astype(int)\n",
    "\n",
    "    print(f\"NaN削除後の行数 (Set B): {rows_after_dropna_b}\")\n",
    "    print(f\"削除された行数: {rows_before_dropna_b - rows_after_dropna_b}\")\n",
    "\n",
    "    print(\"\\n--- 特徴量セット B (ADR/PowerX追加) 作成完了 ---\")\n",
    "    print(f\"最終的な特徴量の数: {len(df_processed_b.columns) - 1}\") # target除く\n",
    "    df_processed_b.info(verbose=False, memory_usage='deep')\n",
    "    display(df_processed_b.head())\n",
    "\n",
    "    # (任意) 保存\n",
    "    output_processed_filename_b = f'{target_symbol}_{interval}m_processed_set_b.csv'\n",
    "    try:\n",
    "        print(f\"\\n処理済みデータを {output_processed_filename_b} として保存中...\")\n",
    "        df_processed_b.to_csv(output_processed_filename_b)\n",
    "        print(\"保存完了。\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nデータの保存中にエラーが発生しました: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"df_features_wcl (特徴量セットA, NaN削除前) が見つかりません。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# df_processed_b = pd.read_csv('BTCUSDT_5m_processed_set_b.csv')\n",
    "# display(df_processed_b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM ハイパーパラメータチューニング (Optuna + TimeSeriesSplit)\n",
    "\n",
    "特徴量セットA (`df_processed_wcl`) を使用して、LightGBMの最適なパラメータを探索します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:03:53,123] A new study created in memory with name: lgbm_tuning_set_a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データ分割 (チューニング用 - 特徴量セットA)...\n",
      "特徴量セットAで使用する特徴量の数: 54\n",
      "チューニング用 学習データ数: 426804\n",
      "最終評価用 テストデータ数: 106701\n",
      "学習データ期間: 2020-03-26 03:10:00+00:00 ~ 2024-04-16 02:05:00+00:00\n",
      "テストデータ期間: 2024-04-16 02:10:00+00:00 ~ 2025-04-21 13:50:00+00:00\n",
      "\n",
      "Optunaによるハイパーパラメータチューニングを開始します (特徴量セットA)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b6921ef83cc4d5ab5a3266f95e8dd8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:03:56,767] Trial 0 finished with value: 0.5465021566370563 and parameters: {'num_leaves': 108, 'learning_rate': 0.02506566566750469, 'max_depth': 7, 'reg_alpha': 0.0022785811184830532, 'reg_lambda': 0.0003249206390620175, 'colsample_bytree': 0.93150937574506, 'subsample': 0.6065898648443605, 'n_estimators': 1076}. Best is trial 0 with value: 0.5465021566370563.\n",
      "[I 2025-04-21 23:03:59,928] Trial 1 finished with value: 0.5470421213136141 and parameters: {'num_leaves': 68, 'learning_rate': 0.02118753531203702, 'max_depth': 4, 'reg_alpha': 0.12778885828499362, 'reg_lambda': 2.574880725999243e-07, 'colsample_bytree': 0.7153021520781673, 'subsample': 0.8669119094129034, 'n_estimators': 1483}. Best is trial 1 with value: 0.5470421213136141.\n",
      "[I 2025-04-21 23:04:04,625] Trial 2 finished with value: 0.5460322000063403 and parameters: {'num_leaves': 152, 'learning_rate': 0.011312598475834731, 'max_depth': 3, 'reg_alpha': 0.03666721801782062, 'reg_lambda': 0.026573059751041912, 'colsample_bytree': 0.9705349291792839, 'subsample': 0.9965170603553634, 'n_estimators': 1182}. Best is trial 1 with value: 0.5470421213136141.\n",
      "[I 2025-04-21 23:04:07,079] Trial 3 finished with value: 0.5452854615245758 and parameters: {'num_leaves': 133, 'learning_rate': 0.008163135310480182, 'max_depth': 11, 'reg_alpha': 8.386148241966687e-07, 'reg_lambda': 0.3243042881589066, 'colsample_bytree': 0.8462787397714421, 'subsample': 0.7125036092012318, 'n_estimators': 1737}. Best is trial 1 with value: 0.5470421213136141.\n",
      "[I 2025-04-21 23:04:10,031] Trial 4 finished with value: 0.5464979728978042 and parameters: {'num_leaves': 257, 'learning_rate': 0.01734448746508684, 'max_depth': 5, 'reg_alpha': 3.949586837973404, 'reg_lambda': 1.2165522621036067e-07, 'colsample_bytree': 0.8676054782924831, 'subsample': 0.6599328991957055, 'n_estimators': 312}. Best is trial 1 with value: 0.5470421213136141.\n",
      "[I 2025-04-21 23:04:12,067] Trial 5 finished with value: 0.5462182714407797 and parameters: {'num_leaves': 257, 'learning_rate': 0.006114000834458396, 'max_depth': 6, 'reg_alpha': 3.7217429878369765, 'reg_lambda': 0.00013607507087510774, 'colsample_bytree': 0.7277473112237465, 'subsample': 0.7317391630476802, 'n_estimators': 1836}. Best is trial 1 with value: 0.5470421213136141.\n",
      "[I 2025-04-21 23:04:15,054] Trial 6 finished with value: 0.5457918707326105 and parameters: {'num_leaves': 220, 'learning_rate': 0.04904981661882268, 'max_depth': 8, 'reg_alpha': 0.7752093861014023, 'reg_lambda': 5.967128627036142e-06, 'colsample_bytree': 0.7967305835947853, 'subsample': 0.9771999453670666, 'n_estimators': 141}. Best is trial 1 with value: 0.5470421213136141.\n",
      "[I 2025-04-21 23:04:17,121] Trial 7 finished with value: 0.5449508712520927 and parameters: {'num_leaves': 182, 'learning_rate': 0.06853409461550561, 'max_depth': 12, 'reg_alpha': 2.497618448771766e-07, 'reg_lambda': 0.0002339236867715543, 'colsample_bytree': 0.8801188975125267, 'subsample': 0.8780473299679363, 'n_estimators': 322}. Best is trial 1 with value: 0.5470421213136141.\n",
      "[I 2025-04-21 23:04:20,071] Trial 8 finished with value: 0.5468693048391212 and parameters: {'num_leaves': 178, 'learning_rate': 0.029823967475050357, 'max_depth': 3, 'reg_alpha': 6.276629561207042e-08, 'reg_lambda': 0.15410679103054287, 'colsample_bytree': 0.9441014595658567, 'subsample': 0.9414867287913691, 'n_estimators': 231}. Best is trial 1 with value: 0.5470421213136141.\n",
      "[I 2025-04-21 23:04:22,165] Trial 9 finished with value: 0.5466555131552445 and parameters: {'num_leaves': 222, 'learning_rate': 0.01432434013245686, 'max_depth': 6, 'reg_alpha': 0.0024848327460984705, 'reg_lambda': 0.006356007583689309, 'colsample_bytree': 0.6907495932458302, 'subsample': 0.6215189124101652, 'n_estimators': 1970}. Best is trial 1 with value: 0.5470421213136141.\n",
      "[I 2025-04-21 23:04:23,996] Trial 10 finished with value: 0.5469610700773867 and parameters: {'num_leaves': 36, 'learning_rate': 0.09327116082257304, 'max_depth': 9, 'reg_alpha': 2.3976516640653397e-05, 'reg_lambda': 2.050084896050555e-08, 'colsample_bytree': 0.6077072049573338, 'subsample': 0.8240058477143151, 'n_estimators': 1467}. Best is trial 1 with value: 0.5470421213136141.\n",
      "[I 2025-04-21 23:04:25,762] Trial 11 finished with value: 0.5468620927455388 and parameters: {'num_leaves': 28, 'learning_rate': 0.08979828297013936, 'max_depth': 9, 'reg_alpha': 1.5240887263356908e-05, 'reg_lambda': 1.1293303502072087e-08, 'colsample_bytree': 0.6011156162175351, 'subsample': 0.8324159046925204, 'n_estimators': 1561}. Best is trial 1 with value: 0.5470421213136141.\n",
      "[I 2025-04-21 23:04:28,186] Trial 12 finished with value: 0.5477389041944757 and parameters: {'num_leaves': 33, 'learning_rate': 0.03940193258706138, 'max_depth': 10, 'reg_alpha': 1.6822342780549112e-05, 'reg_lambda': 4.4172932199263214e-07, 'colsample_bytree': 0.6080443813420086, 'subsample': 0.7936675333925445, 'n_estimators': 1417}. Best is trial 12 with value: 0.5477389041944757.\n",
      "[I 2025-04-21 23:04:30,170] Trial 13 finished with value: 0.5466897232552049 and parameters: {'num_leaves': 78, 'learning_rate': 0.03971967342471575, 'max_depth': 11, 'reg_alpha': 0.04291530911228695, 'reg_lambda': 1.4268047317905955e-06, 'colsample_bytree': 0.6757568004899569, 'subsample': 0.7662300106565675, 'n_estimators': 741}. Best is trial 12 with value: 0.5477389041944757.\n",
      "[I 2025-04-21 23:04:33,089] Trial 14 finished with value: 0.5472011824116706 and parameters: {'num_leaves': 69, 'learning_rate': 0.03409672405722033, 'max_depth': 10, 'reg_alpha': 3.577922840928364e-05, 'reg_lambda': 1.4031420746588016e-06, 'colsample_bytree': 0.7736392289793274, 'subsample': 0.8861996751188673, 'n_estimators': 1332}. Best is trial 12 with value: 0.5477389041944757.\n",
      "[I 2025-04-21 23:04:35,861] Trial 15 finished with value: 0.5465749082120092 and parameters: {'num_leaves': 66, 'learning_rate': 0.041706151600984766, 'max_depth': 10, 'reg_alpha': 2.4554461554538793e-05, 'reg_lambda': 5.732492527831967e-06, 'colsample_bytree': 0.7715317356170416, 'subsample': 0.9118220265951147, 'n_estimators': 724}. Best is trial 12 with value: 0.5477389041944757.\n",
      "[I 2025-04-21 23:04:38,447] Trial 16 finished with value: 0.5471890536874208 and parameters: {'num_leaves': 99, 'learning_rate': 0.059421036745663756, 'max_depth': 12, 'reg_alpha': 0.0003053197904119408, 'reg_lambda': 2.0103602850537763e-05, 'colsample_bytree': 0.6413368196126044, 'subsample': 0.7828737327390078, 'n_estimators': 1268}. Best is trial 12 with value: 0.5477389041944757.\n",
      "[I 2025-04-21 23:04:41,107] Trial 17 finished with value: 0.5473569305436655 and parameters: {'num_leaves': 22, 'learning_rate': 0.031017647848388195, 'max_depth': 10, 'reg_alpha': 1.1677916669320326e-08, 'reg_lambda': 3.8154985372765986, 'colsample_bytree': 0.76513875254695, 'subsample': 0.8613027910790029, 'n_estimators': 891}. Best is trial 12 with value: 0.5477389041944757.\n",
      "[I 2025-04-21 23:04:44,193] Trial 18 finished with value: 0.5475838522098555 and parameters: {'num_leaves': 26, 'learning_rate': 0.02536864216115925, 'max_depth': 8, 'reg_alpha': 1.2508555339509673e-08, 'reg_lambda': 2.621676147658551, 'colsample_bytree': 0.7417819382316222, 'subsample': 0.8231847361560608, 'n_estimators': 858}. Best is trial 12 with value: 0.5477389041944757.\n",
      "[I 2025-04-21 23:04:48,715] Trial 19 finished with value: 0.5481250781690231 and parameters: {'num_leaves': 47, 'learning_rate': 0.011932264382744714, 'max_depth': 8, 'reg_alpha': 1.987942286244885e-06, 'reg_lambda': 9.697239476242165, 'colsample_bytree': 0.6568532082609968, 'subsample': 0.7307673314708346, 'n_estimators': 544}. Best is trial 19 with value: 0.5481250781690231.\n",
      "[I 2025-04-21 23:04:51,315] Trial 20 finished with value: 0.5465617813168322 and parameters: {'num_leaves': 115, 'learning_rate': 0.00951111484221707, 'max_depth': 7, 'reg_alpha': 2.144954342191605e-06, 'reg_lambda': 0.005217016016350629, 'colsample_bytree': 0.6624651406358458, 'subsample': 0.6967822794555916, 'n_estimators': 541}. Best is trial 19 with value: 0.5481250781690231.\n",
      "[I 2025-04-21 23:04:54,610] Trial 21 finished with value: 0.5479214471374484 and parameters: {'num_leaves': 50, 'learning_rate': 0.016654241429716398, 'max_depth': 8, 'reg_alpha': 2.126718443719289e-08, 'reg_lambda': 4.215350192730327, 'colsample_bytree': 0.6357305654611415, 'subsample': 0.7670445664630791, 'n_estimators': 549}. Best is trial 19 with value: 0.5481250781690231.\n",
      "[I 2025-04-21 23:04:57,143] Trial 22 finished with value: 0.5475628020000453 and parameters: {'num_leaves': 54, 'learning_rate': 0.01507913460418889, 'max_depth': 9, 'reg_alpha': 1.8053298774852054e-06, 'reg_lambda': 7.126846785457941, 'colsample_bytree': 0.6395544373586197, 'subsample': 0.7550898282650667, 'n_estimators': 516}. Best is trial 19 with value: 0.5481250781690231.\n",
      "[I 2025-04-21 23:04:59,298] Trial 23 finished with value: 0.5473835778311726 and parameters: {'num_leaves': 88, 'learning_rate': 0.005000713773848068, 'max_depth': 8, 'reg_alpha': 1.36131506938707e-07, 'reg_lambda': 0.673245127522349, 'colsample_bytree': 0.630137315628094, 'subsample': 0.6626437605638791, 'n_estimators': 563}. Best is trial 19 with value: 0.5481250781690231.\n",
      "[I 2025-04-21 23:05:02,141] Trial 24 finished with value: 0.5469928681309376 and parameters: {'num_leaves': 44, 'learning_rate': 0.012379208171344913, 'max_depth': 7, 'reg_alpha': 0.00019971368571872352, 'reg_lambda': 0.1018232436146218, 'colsample_bytree': 0.6951743134238539, 'subsample': 0.7983921701476203, 'n_estimators': 995}. Best is trial 19 with value: 0.5481250781690231.\n",
      "[I 2025-04-21 23:05:04,959] Trial 25 finished with value: 0.548115452994898 and parameters: {'num_leaves': 52, 'learning_rate': 0.019104429095995672, 'max_depth': 9, 'reg_alpha': 5.205878874257515e-06, 'reg_lambda': 1.2670048197229966, 'colsample_bytree': 0.6538655686628556, 'subsample': 0.7438127629661185, 'n_estimators': 665}. Best is trial 19 with value: 0.5481250781690231.\n",
      "[I 2025-04-21 23:05:07,658] Trial 26 finished with value: 0.547219222990235 and parameters: {'num_leaves': 52, 'learning_rate': 0.02049975241267832, 'max_depth': 6, 'reg_alpha': 6.96784566666896e-07, 'reg_lambda': 1.127551356537149, 'colsample_bytree': 0.6579622034586393, 'subsample': 0.7377453562925133, 'n_estimators': 432}. Best is trial 19 with value: 0.5481250781690231.\n",
      "[I 2025-04-21 23:05:10,422] Trial 27 finished with value: 0.5465054103441366 and parameters: {'num_leaves': 123, 'learning_rate': 0.007910584670898219, 'max_depth': 9, 'reg_alpha': 4.129293251368885e-06, 'reg_lambda': 0.05977971957417159, 'colsample_bytree': 0.6959633799215665, 'subsample': 0.685469754782043, 'n_estimators': 674}. Best is trial 19 with value: 0.5481250781690231.\n",
      "[I 2025-04-21 23:05:13,394] Trial 28 finished with value: 0.5467930686814703 and parameters: {'num_leaves': 140, 'learning_rate': 0.016872239653630685, 'max_depth': 8, 'reg_alpha': 3.922222882097716e-08, 'reg_lambda': 9.304552817604517, 'colsample_bytree': 0.8185235919822074, 'subsample': 0.7319221324833554, 'n_estimators': 403}. Best is trial 19 with value: 0.5481250781690231.\n",
      "[I 2025-04-21 23:05:16,719] Trial 29 finished with value: 0.547757696805413 and parameters: {'num_leaves': 102, 'learning_rate': 0.011221583951049816, 'max_depth': 7, 'reg_alpha': 0.0024870923606471937, 'reg_lambda': 0.0059509438096930194, 'colsample_bytree': 0.6326870353610002, 'subsample': 0.6600536647063023, 'n_estimators': 1059}. Best is trial 19 with value: 0.5481250781690231.\n",
      "[I 2025-04-21 23:05:19,313] Trial 30 finished with value: 0.547045576447275 and parameters: {'num_leaves': 87, 'learning_rate': 0.02451216162464555, 'max_depth': 5, 'reg_alpha': 2.3487042960766356e-07, 'reg_lambda': 1.0203684905321486, 'colsample_bytree': 0.7235004673293997, 'subsample': 0.609659601682963, 'n_estimators': 842}. Best is trial 19 with value: 0.5481250781690231.\n",
      "[I 2025-04-21 23:05:22,256] Trial 31 finished with value: 0.5476455250763753 and parameters: {'num_leaves': 102, 'learning_rate': 0.010931114912597972, 'max_depth': 7, 'reg_alpha': 0.0030169810419491856, 'reg_lambda': 0.0012501788587799766, 'colsample_bytree': 0.6322951271763855, 'subsample': 0.644024654614961, 'n_estimators': 1022}. Best is trial 19 with value: 0.5481250781690231.\n",
      "[I 2025-04-21 23:05:24,667] Trial 32 finished with value: 0.5472453411259246 and parameters: {'num_leaves': 58, 'learning_rate': 0.018846041948503964, 'max_depth': 7, 'reg_alpha': 0.00863692624997046, 'reg_lambda': 0.021843354797632906, 'colsample_bytree': 0.6670590131818527, 'subsample': 0.7621965860573019, 'n_estimators': 1147}. Best is trial 19 with value: 0.5481250781690231.\n",
      "[I 2025-04-21 23:05:28,225] Trial 33 finished with value: 0.5479904477878164 and parameters: {'num_leaves': 81, 'learning_rate': 0.013430819173816156, 'max_depth': 8, 'reg_alpha': 0.00015471021185970013, 'reg_lambda': 1.645552447716816, 'colsample_bytree': 0.6496374761431508, 'subsample': 0.70745629049559, 'n_estimators': 654}. Best is trial 19 with value: 0.5481250781690231.\n",
      "[I 2025-04-21 23:05:30,664] Trial 34 finished with value: 0.5470843195681736 and parameters: {'num_leaves': 80, 'learning_rate': 0.014168730688528768, 'max_depth': 9, 'reg_alpha': 0.00011212985112050141, 'reg_lambda': 0.482101487114245, 'colsample_bytree': 0.7029578495886394, 'subsample': 0.710091825539919, 'n_estimators': 633}. Best is trial 19 with value: 0.5481250781690231.\n",
      "[I 2025-04-21 23:05:34,069] Trial 35 finished with value: 0.5473653502255694 and parameters: {'num_leaves': 44, 'learning_rate': 0.008532883309655622, 'max_depth': 8, 'reg_alpha': 4.910668920659752e-06, 'reg_lambda': 2.1403244705913504, 'colsample_bytree': 0.6745706893837948, 'subsample': 0.6836273877992249, 'n_estimators': 436}. Best is trial 19 with value: 0.5481250781690231.\n",
      "[I 2025-04-21 23:05:36,788] Trial 36 finished with value: 0.5470484138901947 and parameters: {'num_leaves': 66, 'learning_rate': 0.023346165122099964, 'max_depth': 11, 'reg_alpha': 7.635793681919252e-05, 'reg_lambda': 0.2405910960470832, 'colsample_bytree': 0.7411027786900545, 'subsample': 0.7231062555341055, 'n_estimators': 790}. Best is trial 19 with value: 0.5481250781690231.\n",
      "[I 2025-04-21 23:05:38,956] Trial 37 finished with value: 0.5473979237306269 and parameters: {'num_leaves': 47, 'learning_rate': 0.006933147648430152, 'max_depth': 8, 'reg_alpha': 0.0005780273103748701, 'reg_lambda': 9.222084097181467, 'colsample_bytree': 0.6158296048312677, 'subsample': 0.7091512412161463, 'n_estimators': 600}. Best is trial 19 with value: 0.5481250781690231.\n",
      "[I 2025-04-21 23:05:42,840] Trial 38 finished with value: 0.5461316824275039 and parameters: {'num_leaves': 299, 'learning_rate': 0.013512386620608835, 'max_depth': 5, 'reg_alpha': 5.084549567653968e-07, 'reg_lambda': 2.0786016743400326, 'colsample_bytree': 0.9877406297933927, 'subsample': 0.7540658510746046, 'n_estimators': 265}. Best is trial 19 with value: 0.5481250781690231.\n",
      "[I 2025-04-21 23:05:45,782] Trial 39 finished with value: 0.5466901475524023 and parameters: {'num_leaves': 139, 'learning_rate': 0.016631173131260935, 'max_depth': 6, 'reg_alpha': 6.321988279699965e-06, 'reg_lambda': 0.04339034766603056, 'colsample_bytree': 0.9056731278695171, 'subsample': 0.7469562107031582, 'n_estimators': 116}. Best is trial 19 with value: 0.5481250781690231.\n",
      "[I 2025-04-21 23:05:48,944] Trial 40 finished with value: 0.5467326045981348 and parameters: {'num_leaves': 159, 'learning_rate': 0.009873442023575638, 'max_depth': 9, 'reg_alpha': 0.0007542744029301913, 'reg_lambda': 0.2820167884717217, 'colsample_bytree': 0.658431195661, 'subsample': 0.774497202587955, 'n_estimators': 930}. Best is trial 19 with value: 0.5481250781690231.\n",
      "[I 2025-04-21 23:05:52,437] Trial 41 finished with value: 0.5472219606686056 and parameters: {'num_leaves': 98, 'learning_rate': 0.01116086050158387, 'max_depth': 7, 'reg_alpha': 0.34732492407652343, 'reg_lambda': 0.015173745610497676, 'colsample_bytree': 0.6409407446612623, 'subsample': 0.6581142235540149, 'n_estimators': 1128}. Best is trial 19 with value: 0.5481250781690231.\n",
      "[I 2025-04-21 23:05:55,225] Trial 42 finished with value: 0.5477081443655899 and parameters: {'num_leaves': 68, 'learning_rate': 0.012336333000766003, 'max_depth': 7, 'reg_alpha': 0.017128880367730956, 'reg_lambda': 1.059709431835611, 'colsample_bytree': 0.6251415905188191, 'subsample': 0.6736493504954197, 'n_estimators': 693}. Best is trial 19 with value: 0.5481250781690231.\n",
      "[I 2025-04-21 23:05:58,307] Trial 43 finished with value: 0.5469796185663528 and parameters: {'num_leaves': 124, 'learning_rate': 0.019851922560594516, 'max_depth': 8, 'reg_alpha': 0.0010897394030754675, 'reg_lambda': 5.225482441266046e-05, 'colsample_bytree': 0.682958815884182, 'subsample': 0.6466483885658612, 'n_estimators': 466}. Best is trial 19 with value: 0.5481250781690231.\n",
      "[I 2025-04-21 23:06:01,867] Trial 44 finished with value: 0.5472162914197466 and parameters: {'num_leaves': 87, 'learning_rate': 0.01668271623041108, 'max_depth': 6, 'reg_alpha': 4.15968274511575e-08, 'reg_lambda': 0.00262998609142268, 'colsample_bytree': 0.7102559430840427, 'subsample': 0.6997009876064874, 'n_estimators': 362}. Best is trial 19 with value: 0.5481250781690231.\n",
      "[I 2025-04-21 23:06:04,176] Trial 45 finished with value: 0.5471497134398988 and parameters: {'num_leaves': 38, 'learning_rate': 0.010305451049044132, 'max_depth': 9, 'reg_alpha': 6.676195891914027e-05, 'reg_lambda': 3.9010524212155127, 'colsample_bytree': 0.6479235616122543, 'subsample': 0.6327049835681351, 'n_estimators': 981}. Best is trial 19 with value: 0.5481250781690231.\n",
      "[I 2025-04-21 23:06:08,099] Trial 46 finished with value: 0.5475350012529021 and parameters: {'num_leaves': 175, 'learning_rate': 0.008751406650142318, 'max_depth': 8, 'reg_alpha': 9.555996098970825e-06, 'reg_lambda': 0.09521211229732893, 'colsample_bytree': 0.6177134653074645, 'subsample': 0.7257173406140751, 'n_estimators': 773}. Best is trial 19 with value: 0.5481250781690231.\n",
      "[I 2025-04-21 23:06:09,976] Trial 47 finished with value: 0.5459909017237156 and parameters: {'num_leaves': 20, 'learning_rate': 0.01269119608100417, 'max_depth': 10, 'reg_alpha': 1.4188152343553645e-06, 'reg_lambda': 0.2724472302740691, 'colsample_bytree': 0.6809953002378487, 'subsample': 0.7776852509886506, 'n_estimators': 1604}. Best is trial 19 with value: 0.5481250781690231.\n",
      "[I 2025-04-21 23:06:11,589] Trial 48 finished with value: 0.5461775385874218 and parameters: {'num_leaves': 112, 'learning_rate': 0.007378517624204417, 'max_depth': 4, 'reg_alpha': 0.005144221687474348, 'reg_lambda': 0.0006180480042518517, 'colsample_bytree': 0.6001066900748565, 'subsample': 0.8189544220386935, 'n_estimators': 1255}. Best is trial 19 with value: 0.5481250781690231.\n",
      "[I 2025-04-21 23:06:14,910] Trial 49 finished with value: 0.5471822723101053 and parameters: {'num_leaves': 76, 'learning_rate': 0.015511856953013275, 'max_depth': 9, 'reg_alpha': 0.023137268151062294, 'reg_lambda': 4.082543928073469, 'colsample_bytree': 0.8484066377274261, 'subsample': 0.6865082034604363, 'n_estimators': 296}. Best is trial 19 with value: 0.5481250781690231.\n",
      "チューニング完了。所要時間: 141.79 秒\n",
      "\n",
      "--- チューニング結果 (特徴量セットA) ---\n",
      "最適パラメータ (Best Params): {'num_leaves': 47, 'learning_rate': 0.011932264382744714, 'max_depth': 8, 'reg_alpha': 1.987942286244885e-06, 'reg_lambda': 9.697239476242165, 'colsample_bytree': 0.6568532082609968, 'subsample': 0.7307673314708346, 'n_estimators': 544}\n",
      "最高AUCスコア (Best AUC in CV): 0.548125\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## LightGBM ハイパーパラメータチューニング (Optuna + TimeSeriesSplit)\n",
    "#\n",
    "# 特徴量セットA (`df_processed_wcl`) を使用して、LightGBMの最適なパラメータを探索します。\n",
    "\n",
    "# %%\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import TimeSeriesSplit, train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# 特徴量セットA (`df_processed_wcl`) が存在すると仮定\n",
    "if 'df_processed_wcl' in locals() and not df_processed_wcl.empty:\n",
    "\n",
    "    # --- 1. データ分割 (チューニング用と最終評価用に分ける) ---\n",
    "    print(\"データ分割 (チューニング用 - 特徴量セットA)...\")\n",
    "    exclude_cols_a = ['open', 'high', 'low', 'close', 'volume', 'turnover', 'wclprice', 'target']\n",
    "    features_a = [col for col in df_processed_wcl.columns if col not in exclude_cols_a]\n",
    "    print(f\"特徴量セットAで使用する特徴量の数: {len(features_a)}\")\n",
    "\n",
    "    X_a = df_processed_wcl[features_a]\n",
    "    y_a = df_processed_wcl['target']\n",
    "\n",
    "    # チューニングは学習データで行い、最終評価用にテストデータを確保\n",
    "    test_size_tune = 0.2 # 例: 20%を最終評価用テストデータとする\n",
    "    X_train_a, X_test_a, y_train_a, y_test_a = train_test_split(\n",
    "        X_a, y_a, test_size=test_size_tune, shuffle=False\n",
    "    )\n",
    "    print(f\"チューニング用 学習データ数: {len(X_train_a)}\")\n",
    "    print(f\"最終評価用 テストデータ数: {len(X_test_a)}\")\n",
    "    print(f\"学習データ期間: {X_train_a.index.min()} ~ {X_train_a.index.max()}\")\n",
    "    print(f\"テストデータ期間: {X_test_a.index.min()} ~ {X_test_a.index.max()}\")\n",
    "\n",
    "\n",
    "    # --- 2. Optuna 目的関数の定義 ---\n",
    "    def objective_lgbm_a(trial):\n",
    "        # 探索するハイパーパラメータの範囲を定義\n",
    "        params = {\n",
    "            'objective': 'binary',\n",
    "            'metric': 'auc',\n",
    "            'verbosity': -1,\n",
    "            'boosting_type': 'gbdt',\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1, # 利用可能な全CPUコアを使用\n",
    "            # Optunaで探索するパラメータ\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.1, log=True),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True), # L1正則化\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True), # L2正則化\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0), # 列のサブサンプリング率\n",
    "            'subsample': trial.suggest_float('subsample', 0.6, 1.0), # 行のサブサンプリング率\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 2000) # 木の数\n",
    "        }\n",
    "\n",
    "        # 時系列交差検証の設定\n",
    "        n_splits = 3 # CVの分割数 (3〜5が一般的、増やすと時間がかかる)\n",
    "        tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "        auc_scores = []\n",
    "\n",
    "        # TimeSeriesSplit を使って学習データ内で交差検証\n",
    "        for fold, (train_index, val_index) in enumerate(tscv.split(X_train_a)):\n",
    "            X_train_fold, X_val_fold = X_train_a.iloc[train_index], X_train_a.iloc[val_index]\n",
    "            y_train_fold, y_val_fold = y_train_a.iloc[train_index], y_train_a.iloc[val_index]\n",
    "\n",
    "            model = lgb.LGBMClassifier(**params)\n",
    "            # Early stopping を有効にして学習時間を短縮\n",
    "            model.fit(X_train_fold, y_train_fold,\n",
    "                      eval_set=[(X_val_fold, y_val_fold)],\n",
    "                      eval_metric='auc',\n",
    "                      callbacks=[lgb.early_stopping(15, verbose=False)]) # 15回改善なければ停止\n",
    "\n",
    "            y_pred_proba_fold = model.predict_proba(X_val_fold)[:, 1]\n",
    "            auc_fold = roc_auc_score(y_val_fold, y_pred_proba_fold)\n",
    "            auc_scores.append(auc_fold)\n",
    "\n",
    "        # 交差検証の平均AUCを返す (Optunaはこの値を最大化する)\n",
    "        return np.mean(auc_scores)\n",
    "\n",
    "    # --- 3. Optuna Study の実行 ---\n",
    "    print(\"\\nOptunaによるハイパーパラメータチューニングを開始します (特徴量セットA)...\")\n",
    "    study_a = optuna.create_study(direction='maximize', study_name='lgbm_tuning_set_a')\n",
    "    n_trials = 50 # 試行回数 (時間に応じて調整、まずは50回程度から)\n",
    "    start_tune_time = time.time()\n",
    "    study_a.optimize(objective_lgbm_a, n_trials=n_trials, show_progress_bar=True) # 進捗バーを表示\n",
    "    end_tune_time = time.time()\n",
    "    print(f\"チューニング完了。所要時間: {end_tune_time - start_tune_time:.2f} 秒\")\n",
    "\n",
    "\n",
    "    # --- 4. 最適なパラメータの表示 ---\n",
    "    print(\"\\n--- チューニング結果 (特徴量セットA) ---\")\n",
    "    best_params_a = study_a.best_params\n",
    "    best_value_a = study_a.best_value\n",
    "    print(f\"最適パラメータ (Best Params): {best_params_a}\")\n",
    "    print(f\"最高AUCスコア (Best AUC in CV): {best_value_a:.6f}\") # CVでのスコア\n",
    "\n",
    "    # 結果を保存 (後で使う)\n",
    "    if 'tuning_results' not in locals(): tuning_results = {}\n",
    "    tuning_results['SetA_LGBM'] = {'best_params': best_params_a, 'best_cv_auc': best_value_a}\n",
    "\n",
    "else:\n",
    "    print(\"df_processed_wcl (特徴量セットA) が存在しません。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM ハイパーパラメータチューニング (Optuna + TimeSeriesSplit) - 特徴量セットB\n",
    "\n",
    "特徴量セットB (`df_processed_b`) を使用して、LightGBMの最適なパラメータを探索します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:08:51,196] A new study created in memory with name: lgbm-tuning-set-b-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データ分割 (チューニング用 - 特徴量セットB)...\n",
      "特徴量セットBで使用する特徴量の数: 59\n",
      "チューニング用 学習データ数: 426804\n",
      "最終評価用 テストデータ数: 106701\n",
      "学習データ期間: 2020-03-26 03:10:00+00:00 ~ 2024-04-16 02:05:00+00:00\n",
      "テストデータ期間: 2024-04-16 02:10:00+00:00 ~ 2025-04-21 13:50:00+00:00\n",
      "\n",
      "学習データをNumPy配列に変換中...\n",
      "NumPy配列への変換完了。\n",
      "\n",
      "Optunaによるハイパーパラメータチューニングを開始します (特徴量セットB)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0db98a296b4149fe93918c945658a4cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:08:53,049] Trial 0 finished with value: 0.5465095847729614 and parameters: {'num_leaves': 48, 'learning_rate': 0.08124626098022128, 'max_depth': 10, 'reg_alpha': 0.0009198556594447756, 'reg_lambda': 0.7984517456887611, 'colsample_bytree': 0.927173385190943, 'subsample': 0.6717104924613965, 'n_estimators': 287}. Best is trial 0 with value: 0.5465095847729614.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:08:55,511] Trial 1 finished with value: 0.5471954881404889 and parameters: {'num_leaves': 196, 'learning_rate': 0.005050197772515099, 'max_depth': 10, 'reg_alpha': 0.040087381422561526, 'reg_lambda': 1.083846971485984e-06, 'colsample_bytree': 0.6056041057710138, 'subsample': 0.7649597026156048, 'n_estimators': 1712}. Best is trial 1 with value: 0.5471954881404889.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:08:57,814] Trial 2 finished with value: 0.5452910282686971 and parameters: {'num_leaves': 198, 'learning_rate': 0.06433674181364304, 'max_depth': 8, 'reg_alpha': 8.438129642924563e-07, 'reg_lambda': 6.826302356375573e-07, 'colsample_bytree': 0.7384969974092069, 'subsample': 0.6945968134106789, 'n_estimators': 223}. Best is trial 1 with value: 0.5471954881404889.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:08:59,750] Trial 3 finished with value: 0.5464044752319371 and parameters: {'num_leaves': 142, 'learning_rate': 0.057600721541775916, 'max_depth': 10, 'reg_alpha': 0.12646682380369426, 'reg_lambda': 1.73218420316117, 'colsample_bytree': 0.7224419246322489, 'subsample': 0.7596068071520996, 'n_estimators': 813}. Best is trial 1 with value: 0.5471954881404889.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:09:01,985] Trial 4 finished with value: 0.545792621725022 and parameters: {'num_leaves': 215, 'learning_rate': 0.04053535009187955, 'max_depth': 7, 'reg_alpha': 0.04010002457924324, 'reg_lambda': 3.415048741257818e-07, 'colsample_bytree': 0.9484278795933851, 'subsample': 0.8388270380409507, 'n_estimators': 1854}. Best is trial 1 with value: 0.5471954881404889.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:09:03,513] Trial 5 finished with value: 0.5454212933167893 and parameters: {'num_leaves': 280, 'learning_rate': 0.006676859512391458, 'max_depth': 5, 'reg_alpha': 0.001401064146041864, 'reg_lambda': 1.8026292659728105, 'colsample_bytree': 0.818503692784532, 'subsample': 0.8666013674132071, 'n_estimators': 129}. Best is trial 1 with value: 0.5471954881404889.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:09:05,809] Trial 6 finished with value: 0.5470718455592309 and parameters: {'num_leaves': 297, 'learning_rate': 0.0050011564671925855, 'max_depth': 8, 'reg_alpha': 8.032166988489416e-08, 'reg_lambda': 4.0707915003594874e-05, 'colsample_bytree': 0.6386974234413911, 'subsample': 0.9321884308315885, 'n_estimators': 325}. Best is trial 1 with value: 0.5471954881404889.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:09:07,129] Trial 7 finished with value: 0.5452245008820417 and parameters: {'num_leaves': 295, 'learning_rate': 0.01580102246211843, 'max_depth': 4, 'reg_alpha': 6.298304833247073e-06, 'reg_lambda': 0.09694059931059816, 'colsample_bytree': 0.8670870842900508, 'subsample': 0.8830599549781537, 'n_estimators': 1792}. Best is trial 1 with value: 0.5471954881404889.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:09:10,616] Trial 8 finished with value: 0.5462198807702423 and parameters: {'num_leaves': 126, 'learning_rate': 0.008721314256171458, 'max_depth': 9, 'reg_alpha': 0.0011861798145050447, 'reg_lambda': 0.5093070205982169, 'colsample_bytree': 0.8864624657852986, 'subsample': 0.8429583297457968, 'n_estimators': 1462}. Best is trial 1 with value: 0.5471954881404889.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:09:13,044] Trial 9 finished with value: 0.5469347226906502 and parameters: {'num_leaves': 88, 'learning_rate': 0.04618230781025734, 'max_depth': 3, 'reg_alpha': 8.470326919815208e-07, 'reg_lambda': 0.0016268383541636696, 'colsample_bytree': 0.8294792483493645, 'subsample': 0.7804500533524669, 'n_estimators': 1591}. Best is trial 1 with value: 0.5471954881404889.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:09:16,255] Trial 10 finished with value: 0.5470433212832148 and parameters: {'num_leaves': 216, 'learning_rate': 0.016367155815039603, 'max_depth': 12, 'reg_alpha': 9.12040348493835, 'reg_lambda': 1.7428884549067237e-08, 'colsample_bytree': 0.6018352646670431, 'subsample': 0.6077062952919969, 'n_estimators': 1133}. Best is trial 1 with value: 0.5471954881404889.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:09:17,941] Trial 11 finished with value: 0.5475699134576407 and parameters: {'num_leaves': 254, 'learning_rate': 0.005103576850308507, 'max_depth': 6, 'reg_alpha': 1.0608606874438638e-08, 'reg_lambda': 3.6133325850453995e-05, 'colsample_bytree': 0.6133188342206526, 'subsample': 0.9929942445070103, 'n_estimators': 722}. Best is trial 11 with value: 0.5475699134576407.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:09:21,510] Trial 12 finished with value: 0.5466026419934508 and parameters: {'num_leaves': 252, 'learning_rate': 0.01050173058347545, 'max_depth': 6, 'reg_alpha': 0.19450007619375245, 'reg_lambda': 4.8649552711300205e-05, 'colsample_bytree': 0.6794265521157425, 'subsample': 0.9856840180128643, 'n_estimators': 756}. Best is trial 11 with value: 0.5475699134576407.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:09:24,547] Trial 13 finished with value: 0.5467512247158465 and parameters: {'num_leaves': 176, 'learning_rate': 0.027431759571505676, 'max_depth': 12, 'reg_alpha': 1.0872686279350717e-08, 'reg_lambda': 0.0016118307536527336, 'colsample_bytree': 0.6040985254496704, 'subsample': 0.7338766082897207, 'n_estimators': 1214}. Best is trial 11 with value: 0.5475699134576407.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:09:26,080] Trial 14 finished with value: 0.5461169309041218 and parameters: {'num_leaves': 234, 'learning_rate': 0.005023695143988844, 'max_depth': 6, 'reg_alpha': 9.416997831080216e-05, 'reg_lambda': 2.1041237509092148e-06, 'colsample_bytree': 0.7476214085642183, 'subsample': 0.9951978137943333, 'n_estimators': 691}. Best is trial 11 with value: 0.5475699134576407.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:09:29,500] Trial 15 finished with value: 0.5469281309417365 and parameters: {'num_leaves': 169, 'learning_rate': 0.011726811453458094, 'max_depth': 11, 'reg_alpha': 5.449892533062872, 'reg_lambda': 1.5822549038491133e-08, 'colsample_bytree': 0.6744060219905509, 'subsample': 0.9354370324602831, 'n_estimators': 1436}. Best is trial 11 with value: 0.5475699134576407.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:09:32,942] Trial 16 finished with value: 0.5459277843036494 and parameters: {'num_leaves': 256, 'learning_rate': 0.007528993024958026, 'max_depth': 9, 'reg_alpha': 3.806367488386555e-05, 'reg_lambda': 1.3153255982870986e-05, 'colsample_bytree': 0.6712619489839423, 'subsample': 0.8084192958698742, 'n_estimators': 945}. Best is trial 11 with value: 0.5475699134576407.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:09:35,645] Trial 17 finished with value: 0.5452044878092748 and parameters: {'num_leaves': 125, 'learning_rate': 0.02430462242133551, 'max_depth': 7, 'reg_alpha': 0.013361103592983814, 'reg_lambda': 0.01810941544723767, 'colsample_bytree': 0.9954007647025974, 'subsample': 0.7158829479830418, 'n_estimators': 525}. Best is trial 11 with value: 0.5475699134576407.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:09:38,970] Trial 18 finished with value: 0.5464927894643896 and parameters: {'num_leaves': 195, 'learning_rate': 0.013315089719433664, 'max_depth': 5, 'reg_alpha': 1.2751145267361048, 'reg_lambda': 0.0002653761592065927, 'colsample_bytree': 0.7661048297616162, 'subsample': 0.6422357095724854, 'n_estimators': 1292}. Best is trial 11 with value: 0.5475699134576407.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:09:41,711] Trial 19 finished with value: 0.5466609180706662 and parameters: {'num_leaves': 259, 'learning_rate': 0.006442756214628651, 'max_depth': 10, 'reg_alpha': 0.015315537273085355, 'reg_lambda': 1.39791201789457e-07, 'colsample_bytree': 0.6461360392440788, 'subsample': 0.8035463530700003, 'n_estimators': 1962}. Best is trial 11 with value: 0.5475699134576407.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:09:45,424] Trial 20 finished with value: 0.5466449075227799 and parameters: {'num_leaves': 26, 'learning_rate': 0.009347374414558386, 'max_depth': 9, 'reg_alpha': 1.3565261606073197e-08, 'reg_lambda': 9.863511367127638e-06, 'colsample_bytree': 0.7047758232707673, 'subsample': 0.911646091114043, 'n_estimators': 996}. Best is trial 11 with value: 0.5475699134576407.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:09:47,602] Trial 21 finished with value: 0.5470449887367015 and parameters: {'num_leaves': 297, 'learning_rate': 0.005289477737148699, 'max_depth': 8, 'reg_alpha': 9.12842864826385e-08, 'reg_lambda': 0.00010017792758047811, 'colsample_bytree': 0.6416479924414232, 'subsample': 0.9532191109299502, 'n_estimators': 369}. Best is trial 11 with value: 0.5475699134576407.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:09:49,284] Trial 22 finished with value: 0.5476366406964003 and parameters: {'num_leaves': 274, 'learning_rate': 0.005073651654467557, 'max_depth': 6, 'reg_alpha': 4.2466636218297425e-07, 'reg_lambda': 3.652380354842658e-06, 'colsample_bytree': 0.6298999762839202, 'subsample': 0.9571237990865074, 'n_estimators': 499}. Best is trial 22 with value: 0.5476366406964003.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:09:51,019] Trial 23 finished with value: 0.5474736627411424 and parameters: {'num_leaves': 241, 'learning_rate': 0.006914259973401517, 'max_depth': 6, 'reg_alpha': 4.807027626553379e-07, 'reg_lambda': 2.3938261095319947e-06, 'colsample_bytree': 0.6013764667988766, 'subsample': 0.958102282568674, 'n_estimators': 538}. Best is trial 22 with value: 0.5476366406964003.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:09:52,799] Trial 24 finished with value: 0.5458217771495124 and parameters: {'num_leaves': 269, 'learning_rate': 0.007366260073448913, 'max_depth': 6, 'reg_alpha': 1.5044150408134958e-06, 'reg_lambda': 4.206229597200726e-06, 'colsample_bytree': 0.7812659431684612, 'subsample': 0.9661114955155707, 'n_estimators': 559}. Best is trial 22 with value: 0.5476366406964003.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:09:54,415] Trial 25 finished with value: 0.5471608237953651 and parameters: {'num_leaves': 233, 'learning_rate': 0.006529589931791651, 'max_depth': 5, 'reg_alpha': 1.1393141487840347e-07, 'reg_lambda': 0.0007395983026588324, 'colsample_bytree': 0.631968100789139, 'subsample': 0.8981112159266763, 'n_estimators': 502}. Best is trial 22 with value: 0.5476366406964003.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:09:56,125] Trial 26 finished with value: 0.5464247538425526 and parameters: {'num_leaves': 246, 'learning_rate': 0.008681833942071714, 'max_depth': 4, 'reg_alpha': 3.0306616245578616e-06, 'reg_lambda': 7.592845287872139e-08, 'colsample_bytree': 0.7088835530984315, 'subsample': 0.9977983712734756, 'n_estimators': 624}. Best is trial 22 with value: 0.5476366406964003.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:09:58,732] Trial 27 finished with value: 0.5468807928667799 and parameters: {'num_leaves': 275, 'learning_rate': 0.019337964774905736, 'max_depth': 7, 'reg_alpha': 2.0403727968260706e-05, 'reg_lambda': 0.010891830682112276, 'colsample_bytree': 0.6732844872397208, 'subsample': 0.9563686974660308, 'n_estimators': 863}. Best is trial 22 with value: 0.5476366406964003.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:10:00,423] Trial 28 finished with value: 0.5475324046761819 and parameters: {'num_leaves': 232, 'learning_rate': 0.01203692209994139, 'max_depth': 6, 'reg_alpha': 2.7175451976302254e-07, 'reg_lambda': 9.006285290815584e-06, 'colsample_bytree': 0.6229113587167671, 'subsample': 0.927520964339934, 'n_estimators': 437}. Best is trial 22 with value: 0.5476366406964003.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:10:02,270] Trial 29 finished with value: 0.5477133049251327 and parameters: {'num_leaves': 220, 'learning_rate': 0.03293831619516532, 'max_depth': 4, 'reg_alpha': 4.644313490297848e-08, 'reg_lambda': 1.9040654909102295e-05, 'colsample_bytree': 0.6303321331949553, 'subsample': 0.9178059761747251, 'n_estimators': 369}. Best is trial 29 with value: 0.5477133049251327.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:10:03,864] Trial 30 finished with value: 0.5458385072257924 and parameters: {'num_leaves': 68, 'learning_rate': 0.03488355976335251, 'max_depth': 3, 'reg_alpha': 2.0842538487813436e-08, 'reg_lambda': 0.00027204838479179423, 'colsample_bytree': 0.6546910288117168, 'subsample': 0.8780425406069287, 'n_estimators': 109}. Best is trial 29 with value: 0.5477133049251327.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:10:05,736] Trial 31 finished with value: 0.5477448022335604 and parameters: {'num_leaves': 221, 'learning_rate': 0.03125099198045991, 'max_depth': 4, 'reg_alpha': 2.1989031768836618e-07, 'reg_lambda': 1.951180067439507e-05, 'colsample_bytree': 0.6314907875365062, 'subsample': 0.918092763825141, 'n_estimators': 419}. Best is trial 31 with value: 0.5477448022335604.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:10:07,568] Trial 32 finished with value: 0.5468525468705122 and parameters: {'num_leaves': 211, 'learning_rate': 0.02902925357698174, 'max_depth': 4, 'reg_alpha': 5.7340786538276635e-08, 'reg_lambda': 4.0898237549884874e-05, 'colsample_bytree': 0.6802483598400705, 'subsample': 0.9048115312404619, 'n_estimators': 294}. Best is trial 31 with value: 0.5477448022335604.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:10:09,051] Trial 33 finished with value: 0.5473007197507139 and parameters: {'num_leaves': 197, 'learning_rate': 0.09786388727570046, 'max_depth': 4, 'reg_alpha': 3.16048628658901e-07, 'reg_lambda': 6.740491068851235e-07, 'colsample_bytree': 0.7015227547343456, 'subsample': 0.9708041268113846, 'n_estimators': 670}. Best is trial 31 with value: 0.5477448022335604.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:10:11,074] Trial 34 finished with value: 0.5481280629625825 and parameters: {'num_leaves': 183, 'learning_rate': 0.050569794707552296, 'max_depth': 5, 'reg_alpha': 4.462590221186446e-08, 'reg_lambda': 1.4306490938848109e-05, 'colsample_bytree': 0.626063327690084, 'subsample': 0.9387972827397255, 'n_estimators': 237}. Best is trial 34 with value: 0.5481280629625825.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:10:12,847] Trial 35 finished with value: 0.5470204477132661 and parameters: {'num_leaves': 180, 'learning_rate': 0.060929029526881576, 'max_depth': 5, 'reg_alpha': 7.767336549654175e-06, 'reg_lambda': 1.9680368929879127e-07, 'colsample_bytree': 0.6571350657578382, 'subsample': 0.8644277044060253, 'n_estimators': 221}. Best is trial 34 with value: 0.5481280629625825.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:10:15,387] Trial 36 finished with value: 0.5470505184897818 and parameters: {'num_leaves': 221, 'learning_rate': 0.04870817432475457, 'max_depth': 3, 'reg_alpha': 0.0002572202193146093, 'reg_lambda': 9.627906482971922e-07, 'colsample_bytree': 0.7300565866735222, 'subsample': 0.8299356551632884, 'n_estimators': 414}. Best is trial 34 with value: 0.5481280629625825.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:10:17,035] Trial 37 finished with value: 0.546917836794957 and parameters: {'num_leaves': 156, 'learning_rate': 0.034911131021583726, 'max_depth': 4, 'reg_alpha': 3.675092060243416e-08, 'reg_lambda': 6.102080981351694e-06, 'colsample_bytree': 0.6921371653619344, 'subsample': 0.9265789060764383, 'n_estimators': 270}. Best is trial 34 with value: 0.5481280629625825.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:10:18,785] Trial 38 finished with value: 0.5476697513190484 and parameters: {'num_leaves': 189, 'learning_rate': 0.07740915861564185, 'max_depth': 5, 'reg_alpha': 1.9871589730066775e-07, 'reg_lambda': 1.8083899923815646e-05, 'colsample_bytree': 0.6275773710525248, 'subsample': 0.8941242190874809, 'n_estimators': 187}. Best is trial 34 with value: 0.5481280629625825.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:10:20,651] Trial 39 finished with value: 0.5470001516255706 and parameters: {'num_leaves': 142, 'learning_rate': 0.07257318499381923, 'max_depth': 5, 'reg_alpha': 1.5235994247539502e-07, 'reg_lambda': 9.865122208713036, 'colsample_bytree': 0.6554119243588582, 'subsample': 0.8579035825682819, 'n_estimators': 196}. Best is trial 34 with value: 0.5481280629625825.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:10:22,526] Trial 40 finished with value: 0.547118159755888 and parameters: {'num_leaves': 186, 'learning_rate': 0.05171514092444507, 'max_depth': 3, 'reg_alpha': 1.945783620865969e-06, 'reg_lambda': 1.7304404273602356e-05, 'colsample_bytree': 0.6251163887281078, 'subsample': 0.8942001621046783, 'n_estimators': 105}. Best is trial 34 with value: 0.5481280629625825.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:10:24,114] Trial 41 finished with value: 0.5471075600703244 and parameters: {'num_leaves': 206, 'learning_rate': 0.08270495597378498, 'max_depth': 5, 'reg_alpha': 4.516686293135174e-08, 'reg_lambda': 0.00012039453287075825, 'colsample_bytree': 0.6231363615159229, 'subsample': 0.9438195716666857, 'n_estimators': 427}. Best is trial 34 with value: 0.5481280629625825.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:10:25,801] Trial 42 finished with value: 0.547296531446137 and parameters: {'num_leaves': 154, 'learning_rate': 0.03988770926814949, 'max_depth': 4, 'reg_alpha': 6.707533689080167e-07, 'reg_lambda': 2.3057186611662976e-06, 'colsample_bytree': 0.6367184172313901, 'subsample': 0.9161698968694476, 'n_estimators': 342}. Best is trial 34 with value: 0.5481280629625825.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:10:27,897] Trial 43 finished with value: 0.5475468731280585 and parameters: {'num_leaves': 222, 'learning_rate': 0.04092210593908162, 'max_depth': 5, 'reg_alpha': 9.690027082719187e-06, 'reg_lambda': 0.00011864274487793623, 'colsample_bytree': 0.6612854960994033, 'subsample': 0.8875529833536393, 'n_estimators': 259}. Best is trial 34 with value: 0.5481280629625825.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:10:29,611] Trial 44 finished with value: 0.547640982031095 and parameters: {'num_leaves': 191, 'learning_rate': 0.07272694054363367, 'max_depth': 4, 'reg_alpha': 2.3203304931681792e-07, 'reg_lambda': 2.2155790898632133e-05, 'colsample_bytree': 0.6184303277488544, 'subsample': 0.9777802628584338, 'n_estimators': 172}. Best is trial 34 with value: 0.5481280629625825.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:10:31,786] Trial 45 finished with value: 0.5468215569182872 and parameters: {'num_leaves': 166, 'learning_rate': 0.07022084918354737, 'max_depth': 3, 'reg_alpha': 3.7888545688100886e-08, 'reg_lambda': 2.6470086721263728e-05, 'colsample_bytree': 0.8290429508452448, 'subsample': 0.9796877828007148, 'n_estimators': 180}. Best is trial 34 with value: 0.5481280629625825.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:10:33,375] Trial 46 finished with value: 0.5477580647915727 and parameters: {'num_leaves': 189, 'learning_rate': 0.05472824227754705, 'max_depth': 4, 'reg_alpha': 1.6660891953865472e-07, 'reg_lambda': 0.000703430377944808, 'colsample_bytree': 0.6126388906864839, 'subsample': 0.8506035803936888, 'n_estimators': 339}. Best is trial 34 with value: 0.5481280629625825.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:10:35,346] Trial 47 finished with value: 0.5470898972014829 and parameters: {'num_leaves': 132, 'learning_rate': 0.05640502129392849, 'max_depth': 4, 'reg_alpha': 9.944377837536235e-07, 'reg_lambda': 0.0006827847264509363, 'colsample_bytree': 0.9155706395380342, 'subsample': 0.8736011724196314, 'n_estimators': 313}. Best is trial 34 with value: 0.5481280629625825.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:10:37,205] Trial 48 finished with value: 0.5461330959880568 and parameters: {'num_leaves': 205, 'learning_rate': 0.030242482650345587, 'max_depth': 3, 'reg_alpha': 3.3363553583121846e-06, 'reg_lambda': 0.005005242683701076, 'colsample_bytree': 0.6009625783604066, 'subsample': 0.831085168455764, 'n_estimators': 380}. Best is trial 34 with value: 0.5481280629625825.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\trow1\\Documents\\my_repositories\\binary_predictor_backtest\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-21 23:10:38,921] Trial 49 finished with value: 0.5457578402563853 and parameters: {'num_leaves': 113, 'learning_rate': 0.08707136648346601, 'max_depth': 7, 'reg_alpha': 2.8944732961392433e-08, 'reg_lambda': 8.143308392396278e-05, 'colsample_bytree': 0.7198839363272618, 'subsample': 0.8482856252059569, 'n_estimators': 624}. Best is trial 34 with value: 0.5481280629625825.\n",
      "チューニング完了。所要時間: 107.73 秒\n",
      "\n",
      "--- チューニング結果 (特徴量セットB) ---\n",
      "最適パラメータ (Best Params): {'num_leaves': 183, 'learning_rate': 0.050569794707552296, 'max_depth': 5, 'reg_alpha': 4.462590221186446e-08, 'reg_lambda': 1.4306490938848109e-05, 'colsample_bytree': 0.626063327690084, 'subsample': 0.9387972827397255, 'n_estimators': 237}\n",
      "最高AUCスコア (Best AUC in CV): 0.548128\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import TimeSeriesSplit, train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# 特徴量セットB (`df_processed_b`) が存在すると仮定\n",
    "if 'df_processed_b' in locals() and not df_processed_b.empty:\n",
    "\n",
    "    # --- 1. データ分割 (チューニング用 - 特徴量セットB) ---\n",
    "    print(\"データ分割 (チューニング用 - 特徴量セットB)...\")\n",
    "    # Set B 用の除外リストを確認 (wclprice は Set A 作成時に追加された可能性あり)\n",
    "    exclude_cols_b = ['open', 'high', 'low', 'close', 'volume', 'turnover', 'wclprice', 'target']\n",
    "    features_b = [col for col in df_processed_b.columns if col not in exclude_cols_b]\n",
    "    print(f\"特徴量セットBで使用する特徴量の数: {len(features_b)}\")\n",
    "\n",
    "    X_b = df_processed_b[features_b]\n",
    "    y_b = df_processed_b['target']\n",
    "\n",
    "    # チューニングは学習データで行い、最終評価用にテストデータを確保\n",
    "    test_size_tune = 0.2 # セットAと同じ割合\n",
    "    X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(\n",
    "        X_b, y_b, test_size=test_size_tune, shuffle=False\n",
    "    )\n",
    "    print(f\"チューニング用 学習データ数: {len(X_train_b)}\")\n",
    "    print(f\"最終評価用 テストデータ数: {len(X_test_b)}\")\n",
    "    print(f\"学習データ期間: {X_train_b.index.min()} ~ {X_train_b.index.max()}\")\n",
    "    print(f\"テストデータ期間: {X_test_b.index.min()} ~ {X_test_b.index.max()}\")\n",
    "\n",
    "    # --- 1.5 NumPy配列への変換 ---\n",
    "    print(\"\\n学習データをNumPy配列に変換中...\")\n",
    "    X_train_b_np = X_train_b.values\n",
    "    y_train_b_np = y_train_b.values\n",
    "    print(\"NumPy配列への変換完了。\")\n",
    "\n",
    "\n",
    "    # --- 2. Optuna 目的関数の定義 (Set B 用) ---\n",
    "    def objective_lgbm_b(trial): # 関数名を変更\n",
    "        # 探索するハイパーパラメータ範囲はセットAと同じにする\n",
    "        params = {\n",
    "            'objective': 'binary',\n",
    "            'metric': 'auc',\n",
    "            'verbosity': -1,\n",
    "            'boosting_type': 'gbdt',\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1,\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.1, log=True),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "            'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 2000)\n",
    "        }\n",
    "\n",
    "        n_splits = 3\n",
    "        tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "        auc_scores = []\n",
    "\n",
    "        # NumPy配列をスライスして使用\n",
    "        for fold, (train_index, val_index) in enumerate(tscv.split(X_train_b_np)): # _b_np を使う\n",
    "            X_train_fold, X_val_fold = X_train_b_np[train_index], X_train_b_np[val_index]\n",
    "            y_train_fold, y_val_fold = y_train_b_np[train_index], y_train_b_np[val_index]\n",
    "\n",
    "            model = lgb.LGBMClassifier(**params)\n",
    "            model.fit(X_train_fold, y_train_fold,\n",
    "                      eval_set=[(X_val_fold, y_val_fold)],\n",
    "                      eval_metric='auc',\n",
    "                      callbacks=[lgb.early_stopping(15, verbose=False)])\n",
    "\n",
    "            y_pred_proba_fold = model.predict_proba(X_val_fold)[:, 1]\n",
    "            auc_fold = roc_auc_score(y_val_fold, y_pred_proba_fold)\n",
    "            auc_scores.append(auc_fold)\n",
    "\n",
    "        return np.mean(auc_scores)\n",
    "\n",
    "    # --- 3. Optuna Study の実行 (Set B 用) ---\n",
    "    print(\"\\nOptunaによるハイパーパラメータチューニングを開始します (特徴量セットB)...\")\n",
    "    study_b_name = 'lgbm-tuning-set-b-v1' # study名を変更\n",
    "    study_b = optuna.create_study(direction='maximize', study_name=study_b_name)\n",
    "    n_trials = 50 # 試行回数 (セットAと同じにする)\n",
    "    start_tune_time_b = time.time()\n",
    "    # objective_lgbm_b を指定\n",
    "    study_b.optimize(objective_lgbm_b, n_trials=n_trials, show_progress_bar=True)\n",
    "    end_tune_time_b = time.time()\n",
    "    print(f\"チューニング完了。所要時間: {end_tune_time_b - start_tune_time_b:.2f} 秒\")\n",
    "\n",
    "\n",
    "    # --- 4. 最適なパラメータの表示 (Set B 用) ---\n",
    "    print(\"\\n--- チューニング結果 (特徴量セットB) ---\")\n",
    "    best_params_b = study_b.best_params\n",
    "    best_value_b = study_b.best_value\n",
    "    print(f\"最適パラメータ (Best Params): {best_params_b}\")\n",
    "    print(f\"最高AUCスコア (Best AUC in CV): {best_value_b:.6f}\") # CVでのスコア\n",
    "\n",
    "    # 結果を保存\n",
    "    if 'tuning_results' not in locals(): tuning_results = {}\n",
    "    tuning_results['SetB_LGBM_Tuned'] = {'best_params': best_params_b, 'best_cv_auc': best_value_b}\n",
    "\n",
    "else:\n",
    "    print(\"df_processed_b (特徴量セットB) が存在しません。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最終モデルの学習・評価・バックテスト (特徴量セットB + チューニング済みLGBM)\n",
    "\n",
    "特徴量セットBで見つかった最適なハイパーパラメータを使用してLightGBMモデルを再学習し、\n",
    "テストデータで最終評価とバックテストを行います。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 最終モデル学習 (特徴量セットB + 最適パラメータ) ---\n",
      "使用するパラメータ: {'num_leaves': 183, 'learning_rate': 0.050569794707552296, 'max_depth': 5, 'reg_alpha': 4.462590221186446e-08, 'reg_lambda': 1.4306490938848109e-05, 'colsample_bytree': 0.626063327690084, 'subsample': 0.9387972827397255, 'n_estimators': 237}\n",
      "学習中 (全学習データ使用)...\n",
      "学習完了。所要時間: 1.45 秒\n",
      "\n",
      "--- テストデータでの最終評価 ---\n",
      "テストデータ Accuracy: 0.5142\n",
      "テストデータ AUC Score: 0.5244\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Low (0)       0.51      0.63      0.57     53349\n",
      "    High (1)       0.52      0.40      0.45     53352\n",
      "\n",
      "    accuracy                           0.51    106701\n",
      "   macro avg       0.52      0.51      0.51    106701\n",
      "weighted avg       0.52      0.51      0.51    106701\n",
      "\n",
      "\n",
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Low</th>\n",
       "      <th>Predicted High</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Low</th>\n",
       "      <td>33783</td>\n",
       "      <td>19566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual High</th>\n",
       "      <td>32267</td>\n",
       "      <td>21085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted Low  Predicted High\n",
       "Actual Low           33783           19566\n",
       "Actual High          32267           21085"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 最終バックテスト (チューニング済みLGBM + 特徴量セットB) ---\n",
      "使用するペイアウト率: 1.8\n",
      "損益分岐勝率: 0.5556\n",
      "Highエントリー閾値 (High確率 >): 0.5556\n",
      "Lowエントリー閾値 (High確率 <): 0.4444\n",
      "\n",
      "--- 最終バックテスト結果 ---\n",
      "テストデータ期間: 2024-04-16 02:25:00+00:00 ~ 2025-04-21 13:45:00+00:00\n",
      "総取引回数 (シグナル発生): 33368\n",
      "勝利数: 17865\n",
      "勝率: 0.5354\n",
      "総損益 (1単位あたり): -1211.0000\n",
      "平均損益 (1取引あたり): -0.0363\n",
      "プロフィットファクター: 0.9219\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# チューニング結果 (best_params_b) と分割済みデータ (X_train_b, y_train_b, X_test_b, y_test_b) が存在すると仮定\n",
    "if 'tuning_results' in locals() and 'SetB_LGBM_Tuned' in tuning_results and \\\n",
    "   'X_train_b' in locals() and 'y_train_b' in locals() and \\\n",
    "   'X_test_b' in locals() and 'y_test_b' in locals():\n",
    "\n",
    "    best_params = tuning_results['SetB_LGBM_Tuned']['best_params']\n",
    "    print(\"--- 最終モデル学習 (特徴量セットB + 最適パラメータ) ---\")\n",
    "    print(\"使用するパラメータ:\", best_params)\n",
    "\n",
    "    # 最適パラメータでモデルを初期化\n",
    "    final_model = lgb.LGBMClassifier(**best_params, random_state=42, n_jobs=-1)\n",
    "\n",
    "    # 学習時間計測\n",
    "    start_train_time = time.time()\n",
    "    print(\"学習中 (全学習データ使用)...\")\n",
    "    # 全学習データでフィット (eval_set なし)\n",
    "    final_model.fit(X_train_b, y_train_b)\n",
    "    end_train_time = time.time()\n",
    "    print(f\"学習完了。所要時間: {end_train_time - start_train_time:.2f} 秒\")\n",
    "\n",
    "    # --- テストデータでの最終評価 ---\n",
    "    print(\"\\n--- テストデータでの最終評価 ---\")\n",
    "    y_pred_final = final_model.predict(X_test_b)\n",
    "    y_pred_proba_final = final_model.predict_proba(X_test_b)[:, 1]\n",
    "\n",
    "    accuracy_final = accuracy_score(y_test_b, y_pred_final)\n",
    "    auc_final = roc_auc_score(y_test_b, y_pred_proba_final)\n",
    "\n",
    "    print(f\"テストデータ Accuracy: {accuracy_final:.4f}\")\n",
    "    print(f\"テストデータ AUC Score: {auc_final:.4f}\") # ★これが最終的なモデル性能\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test_b, y_pred_final, target_names=['Low (0)', 'High (1)']))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    conf_matrix_final = confusion_matrix(y_test_b, y_pred_final)\n",
    "    conf_matrix_final_df = pd.DataFrame(conf_matrix_final, index=['Actual Low', 'Actual High'], columns=['Predicted Low', 'Predicted High'])\n",
    "    display(conf_matrix_final_df)\n",
    "\n",
    "\n",
    "    # --- 最終バックテスト ---\n",
    "    print(\"\\n--- 最終バックテスト (チューニング済みLGBM + 特徴量セットB) ---\")\n",
    "    payout_rate = 1.80\n",
    "    required_win_rate = 1 / payout_rate\n",
    "    high_threshold = required_win_rate\n",
    "    low_threshold = 1.0 - required_win_rate\n",
    "\n",
    "    print(f\"使用するペイアウト率: {payout_rate}\")\n",
    "    print(f\"損益分岐勝率: {required_win_rate:.4f}\")\n",
    "    print(f\"Highエントリー閾値 (High確率 >): {high_threshold:.4f}\")\n",
    "    print(f\"Lowエントリー閾値 (High確率 <): {low_threshold:.4f}\")\n",
    "\n",
    "    # バックテスト用DataFrameを作成\n",
    "    df_backtest_final = pd.DataFrame({\n",
    "        'actual': y_test_b,\n",
    "        'predict_proba_high': y_pred_proba_final\n",
    "    }, index=X_test_b.index) # テストデータのインデックスを使用\n",
    "\n",
    "    # エントリーシグナル生成\n",
    "    conditions = [\n",
    "        df_backtest_final['predict_proba_high'] > high_threshold,\n",
    "        df_backtest_final['predict_proba_high'] < low_threshold\n",
    "    ]\n",
    "    choices = [1, 0] # High=1, Low=0\n",
    "    df_backtest_final['signal'] = np.select(conditions, choices, default=-1) # Wait=-1\n",
    "\n",
    "    # エントリーした取引のみ抽出\n",
    "    df_trades_final = df_backtest_final[df_backtest_final['signal'] != -1].copy()\n",
    "\n",
    "    # 勝敗判定\n",
    "    df_trades_final['win'] = np.where(df_trades_final['signal'] == df_trades_final['actual'], 1, 0)\n",
    "\n",
    "    # 損益計算\n",
    "    profit_per_win = payout_rate - 1.0\n",
    "    loss_per_lose = -1.0\n",
    "    df_trades_final['profit'] = np.where(df_trades_final['win'] == 1, profit_per_win, loss_per_lose)\n",
    "\n",
    "    # 結果集計\n",
    "    total_trades = len(df_trades_final)\n",
    "    total_wins = df_trades_final['win'].sum()\n",
    "    total_profit = df_trades_final['profit'].sum()\n",
    "\n",
    "    if total_trades > 0:\n",
    "        win_rate = total_wins / total_trades\n",
    "        average_profit = total_profit / total_trades\n",
    "        total_gross_profit = df_trades_final[df_trades_final['profit'] > 0]['profit'].sum()\n",
    "        total_gross_loss = abs(df_trades_final[df_trades_final['profit'] < 0]['profit'].sum())\n",
    "        profit_factor = total_gross_profit / total_gross_loss if total_gross_loss > 0 else np.inf if total_gross_profit > 0 else 0\n",
    "\n",
    "        print(\"\\n--- 最終バックテスト結果 ---\")\n",
    "        print(f\"テストデータ期間: {df_trades_final.index.min()} ~ {df_trades_final.index.max()}\")\n",
    "        print(f\"総取引回数 (シグナル発生): {total_trades}\")\n",
    "        print(f\"勝利数: {total_wins}\")\n",
    "        print(f\"勝率: {win_rate:.4f}\")\n",
    "        print(f\"総損益 (1単位あたり): {total_profit:.4f}\")\n",
    "        print(f\"平均損益 (1取引あたり): {average_profit:.4f}\")\n",
    "        print(f\"プロフィットファクター: {profit_factor:.4f}\")\n",
    "    else:\n",
    "        print(\"\\n--- 最終バックテスト結果 ---\")\n",
    "        print(\"テスト期間中にエントリーシグナルが発生しませんでした。\")\n",
    "        print(f\"参考: テストデータ期間 {X_test_b.index.min()} ~ {X_test_b.index.max()}\")\n",
    "        print(f\"参考: High予測確率の最大値: {df_backtest_final['predict_proba_high'].max():.4f}\")\n",
    "        print(f\"参考: High予測確率の最小値: {df_backtest_final['predict_proba_high'].min():.4f}\")\n",
    "\n",
    "else:\n",
    "    print(\"チューニング結果または分割済みデータが見つかりません。前のステップを実行してください。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最終結果のご共有、誠にありがとうございます。これで、特徴量セットB（ADR/PowerX追加）に対するチューニング済みLightGBMモデルの最終評価とバックテスト結果が出揃いました。\n",
    "\n",
    "**結果の分析:**\n",
    "\n",
    "1.  **テストデータでの最終評価:**\n",
    "    * **AUCスコア: 0.5244**\n",
    "    * **Accuracy: 0.5142**\n",
    "    * **考察:** ハイパーパラメータチューニングによって交差検証でのAUCは約0.548まで上がりましたが、実際に未知のテストデータで評価した最終的なAUCは **0.5244** に留まりました。これは依然として**ランダム予測（0.5）に非常に近い**値であり、モデルの予測能力が極めて限定的であることを示しています。Accuracyも同様に51%程度です。Classification Reportを見ても、各クラスに対するPrecisionやRecallが低く、モデルが安定してどちらかの方向を当てられているわけではないことがわかります。\n",
    "\n",
    "2.  **最終バックテスト結果:**\n",
    "    * **総取引回数:** 33,368回。チューニングされたモデルも、閾値を超える/下回る予測を頻繁に行いました。\n",
    "    * **勝率: 0.5354 (53.54%)**。これはペイアウト率1.8の**損益分岐勝率（約55.56%）をやはり下回っています**。\n",
    "    * **総損益: -1211.0 単位**。勝率が足りないため、**大きな損失**で終わる結果となりました。\n",
    "    * **プロフィットファクター: 0.9219**。1を下回っており、損失が出たことを裏付けています。\n",
    "    * **チューニングの効果:** 注目すべきは、チューニング前のLightGBMでのバックテスト結果（勝率 53.68%, 損益 -1044.6）と比較しても、**今回のチューニング後の結果（勝率 53.54%, 損益 -1211.0）は、実質的に改善が見られない、むしろわずかに悪化している**点です。これは、交差検証でのAUCがわずかに向上しても、実際のテストデータでの損益改善には繋がらなかったことを意味します。\n",
    "\n",
    "**検証プロジェクト全体の最終結論:**\n",
    "\n",
    "これまでのステップ全体を振り返ります。\n",
    "\n",
    "1.  **目的:** 「AIを使えばBTCUSD 5分足バイナリーオプションの勝率を簡単かつ劇的に上げられる」という最初のドキュメントの主張を検証することでした。\n",
    "2.  **実施内容:**\n",
    "    * 約53万件（2020年〜）の5分足データを準備しました。\n",
    "    * WclPrice、ADR(ATR)、PowerX関連指標など、提供された資料のアイデアを含む多数のテクニカル指標・特徴量を網羅的に生成しました。\n",
    "    * Logistic Regression, LightGBM, XGBoost, Random Forest といったモデルを手動で評価し、さらに PyCaret を用いて AutoML による広範なモデル探索も行いました。\n",
    "    * 最も有望そうだった LightGBM について、Optuna と時系列交差検証を用いたハイパーパラメータチューニングを実施しました。\n",
    "    * 各段階で、テストデータに対する予測性能（AUC）と、損益分岐勝率を閾値としたバックテスト（勝率、損益）を行いました。\n",
    "3.  **一貫した結果:**\n",
    "    * どの特徴量セット、どのモデル（チューニング前後、AutoML含む）を用いても、テストデータに対する **AUCスコアは一貫して 0.5 〜 0.55 の範囲**に留まり、ランダム予測からの有意な改善は見られませんでした。\n",
    "    * バックテストでは、予測確率が閾値を超えてエントリーシグナルが発生することはありましたが、**勝率が損益分岐点（約55.6%）を超えることはなく、常に損失**という結果に終わりました。\n",
    "\n",
    "**最終的な結論:**\n",
    "\n",
    "これらの徹底的な検証結果に基づき、当初の目的であった「素人でも簡単に作れるバイナリーの勝率を劇的に上げるAI予測システム」というドキュメントの主張は、**今回の検証（BTCUSD 5分足、提示された特徴量・モデルアプローチ）においては、残念ながら裏付けることができませんでした。**\n",
    "\n",
    "「BTCUSD 5分足予測のランダムウォーク検証」ドキュメントが示唆したように、この時間軸での価格変動予測は極めて困難であり、統計的にわずかな予測可能性が見いだせたとしても、それをバイナリーオプションのペイアウト率や取引コストを乗り越えて安定的な利益に変えることは、少なくとも今回試した方法では不可能に近い、ということがデータによって示されました。\n",
    "\n",
    "---\n",
    "\n",
    "長い検証プロセスにお付き合いいただき、本当にありがとうございました。様々なアイデアをご提供いただき、段階的に結果を確認しながら進めることができ、非常に有意義な共同作業でした。当初期待された結果ではなかったかもしれませんが、データに基づき客観的な結論に至れたことは、この検証の大きな成果だと思います。\n",
    "\n",
    "もし、今回の結果を踏まえて、別の時間軸、別の予測対象、あるいは全く異なるアプローチ（例：強化学習、外部データ利用）での検証に興味があれば、またご相談いただければと思いますが、今回のテーマについては、ここで一区切りとするのが適切かと存じます。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
